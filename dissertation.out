\BOOKMARK [0][-]{section*.1}{Acknowledgements}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Distributed\040representations\040of\040language}{chapter.1}% 3
\BOOKMARK [2][-]{subsection.1.1.1}{Distributed\040word-representations}{section.1.1}% 4
\BOOKMARK [2][-]{subsection.1.1.2}{Visually\040grounded\040representations\040of\040words}{section.1.1}% 5
\BOOKMARK [2][-]{subsection.1.1.3}{From\040words\040to\040sentences}{section.1.1}% 6
\BOOKMARK [2][-]{subsection.1.1.4}{Visually\040grounded\040sentence\040representations}{section.1.1}% 7
\BOOKMARK [2][-]{subsection.1.1.5}{Visually\040grounded\040multilingual\040representations}{section.1.1}% 8
\BOOKMARK [2][-]{subsection.1.1.6}{Interpreting\040continuous\040representations}{section.1.1}% 9
\BOOKMARK [0][-]{chapter.2}{Learning\040word\040meanings\040from\040images\040of\040natural\040scenes}{}% 10
\BOOKMARK [1][-]{section.2.1}{Introduction}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.1.1}{Cross-situational\040learning}{section.2.1}% 12
\BOOKMARK [2][-]{subsection.2.1.2}{Learning\040meanings\040from\040images}{section.2.1}% 13
\BOOKMARK [2][-]{subsection.2.1.3}{Our\040study}{section.2.1}% 14
\BOOKMARK [1][-]{section.2.2}{Word\040learning\040model}{chapter.2}% 15
\BOOKMARK [2][-]{subsection.2.2.1}{Visual\040input}{section.2.2}% 16
\BOOKMARK [2][-]{subsection.2.2.2}{Learning\040algorithm}{section.2.2}% 17
\BOOKMARK [2][-]{subsection.2.2.3}{Baseline\040models}{section.2.2}% 18
\BOOKMARK [1][-]{section.2.3}{Experiments}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.3.1}{Image\040datasets}{section.2.3}% 20
\BOOKMARK [2][-]{subsection.2.3.2}{Word\040similarity\040experiments}{section.2.3}% 21
\BOOKMARK [2][-]{subsection.2.3.3}{Effect\040of\040concreteness\040on\040similarity\040judgments}{section.2.3}% 22
\BOOKMARK [2][-]{subsection.2.3.4}{Word\040production}{section.2.3}% 23
\BOOKMARK [3][-]{section*.8}{Multi-word\040image\040descriptions.}{subsection.2.3.4}% 24
\BOOKMARK [3][-]{figure.caption.9}{Single-concept\040image\040descriptions}{subsection.2.3.4}% 25
\BOOKMARK [1][-]{section.2.4}{Results}{chapter.2}% 26
\BOOKMARK [2][-]{subsection.2.4.1}{Word\040similarity}{section.2.4}% 27
\BOOKMARK [3][-]{table.caption.12}{Concreteness}{subsection.2.4.1}% 28
\BOOKMARK [2][-]{subsection.2.4.2}{Word\040production}{section.2.4}% 29
\BOOKMARK [3][-]{section*.15}{Multi-word\040image\040descriptors}{subsection.2.4.2}% 30
\BOOKMARK [3][-]{table.caption.16}{Single-concept\040image\040descriptors}{subsection.2.4.2}% 31
\BOOKMARK [1][-]{section.2.5}{Discussion\040and\040conclusion}{chapter.2}% 32
\BOOKMARK [0][-]{chapter.3}{Representation\040of\040linguistic\040form\040and\040function\040in\040recurrent\040neural\040networks}{}% 33
\BOOKMARK [1][-]{section.3.1}{Introduction}{chapter.3}% 34
\BOOKMARK [1][-]{section.3.2}{Related\040work}{chapter.3}% 35
\BOOKMARK [1][-]{section.3.3}{Models}{chapter.3}% 36
\BOOKMARK [2][-]{subsection.3.3.1}{Gated\040Recurrent\040Neural\040Networks}{section.3.3}% 37
\BOOKMARK [2][-]{subsection.3.3.2}{Imaginet}{section.3.3}% 38
\BOOKMARK [2][-]{subsection.3.3.3}{Unimodal\040language\040model}{section.3.3}% 39
\BOOKMARK [2][-]{subsection.3.3.4}{Sum\040of\040word\040embeddings}{section.3.3}% 40
\BOOKMARK [1][-]{section.3.4}{Experiments}{chapter.3}% 41
\BOOKMARK [2][-]{subsection.3.4.1}{Computing\040Omission\040Scores}{section.3.4}% 42
\BOOKMARK [2][-]{subsection.3.4.2}{Omission\040score\040distributions}{section.3.4}% 43
\BOOKMARK [2][-]{subsection.3.4.3}{Beyond\040Lexical\040Cues}{section.3.4}% 44
\BOOKMARK [3][-]{figure.caption.25}{Sensitivity\040to\040grammatical\040function}{subsection.3.4.3}% 45
\BOOKMARK [3][-]{figure.caption.26}{Sensitivity\040to\040linear\040structure}{subsection.3.4.3}% 46
\BOOKMARK [2][-]{subsection.3.4.4}{Lexical\040versus\040abstract\040contexts}{section.3.4}% 47
\BOOKMARK [1][-]{section.3.5}{Discussion}{chapter.3}% 48
\BOOKMARK [2][-]{subsection.3.5.1}{Generalizing\040to\040other\040architectures}{section.3.5}% 49
\BOOKMARK [2][-]{subsection.3.5.2}{Future\040directions}{section.3.5}% 50
\BOOKMARK [0][-]{chapter.4}{Imagination\040Improves\040Multimodal\040Translation}{}% 51
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 52
\BOOKMARK [1][-]{section.4.2}{Problem\040Formulation}{chapter.4}% 53
\BOOKMARK [1][-]{section.4.3}{Imagination\040Model}{chapter.4}% 54
\BOOKMARK [2][-]{subsection.4.3.1}{Shared\040Encoder}{section.4.3}% 55
\BOOKMARK [2][-]{subsection.4.3.2}{Neural\040Machine\040Translation\040Decoder}{section.4.3}% 56
\BOOKMARK [2][-]{subsection.4.3.3}{Imaginet\040Decoder}{section.4.3}% 57
\BOOKMARK [1][-]{section.4.4}{Data}{chapter.4}% 58
\BOOKMARK [1][-]{section.4.5}{Experiments}{chapter.4}% 59
\BOOKMARK [2][-]{subsection.4.5.1}{Hyperparameters}{section.4.5}% 60
\BOOKMARK [2][-]{subsection.4.5.2}{In-domain\040experiments}{section.4.5}% 61
\BOOKMARK [2][-]{subsection.4.5.3}{External\040described\040image\040data}{section.4.5}% 62
\BOOKMARK [2][-]{subsection.4.5.4}{External\040parallel\040text\040data}{section.4.5}% 63
\BOOKMARK [2][-]{subsection.4.5.5}{Ensemble\040results}{section.4.5}% 64
\BOOKMARK [2][-]{subsection.4.5.6}{Multi30K\0402017\040results}{section.4.5}% 65
\BOOKMARK [2][-]{subsection.4.5.7}{Qualitative\040examples}{section.4.5}% 66
\BOOKMARK [1][-]{section.4.6}{Discussion}{chapter.4}% 67
\BOOKMARK [2][-]{subsection.4.6.1}{Does\040the\040model\040learn\040grounded\040representations?}{section.4.6}% 68
\BOOKMARK [2][-]{subsection.4.6.2}{The\040effect\040of\040visual\040feature\040vectors}{section.4.6}% 69
\BOOKMARK [1][-]{section.4.7}{Related\040work}{chapter.4}% 70
\BOOKMARK [1][-]{section.4.8}{Conclusion}{chapter.4}% 71
\BOOKMARK [0][-]{chapter.5}{Lessons\040learned\040in\040multilingual\040grounded\040language\040learning}{}% 72
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 73
\BOOKMARK [1][-]{section.5.2}{Related\040work}{chapter.5}% 74
\BOOKMARK [1][-]{section.5.3}{Multilingual\040grounded\040learning}{chapter.5}% 75
\BOOKMARK [1][-]{section.5.4}{Experimental\040setup}{chapter.5}% 76
\BOOKMARK [1][-]{section.5.5}{Bilingual\040Experiments}{chapter.5}% 77
\BOOKMARK [2][-]{subsection.5.5.1}{Reproducing\040gella2017image}{section.5.5}% 78
\BOOKMARK [2][-]{subsection.5.5.2}{Translations\040vs.\040independent\040captions}{section.5.5}% 79
\BOOKMARK [2][-]{subsection.5.5.3}{Overlapping\040vs.\040non-overlapping\040images}{section.5.5}% 80
\BOOKMARK [1][-]{section.5.6}{Multilingual\040experiments}{chapter.5}% 81
\BOOKMARK [2][-]{subsection.5.6.1}{Translation\040vs.\040independent\040captions}{section.5.6}% 82
\BOOKMARK [2][-]{subsection.5.6.2}{High-to-low\040resource\040transfer}{section.5.6}% 83
\BOOKMARK [2][-]{subsection.5.6.3}{Bilingual\040vs.\040multilingual}{section.5.6}% 84
\BOOKMARK [1][-]{section.5.7}{Conclusions}{chapter.5}% 85
\BOOKMARK [0][-]{chapter.6}{General\040discussion\040and\040conclusion}{}% 86
\BOOKMARK [0][-]{section*.50}{Summary}{}% 87
\BOOKMARK [0][-]{section*.52}{Publication\040list}{}% 88
\BOOKMARK [0][-]{section*.54}{References}{}% 89
\BOOKMARK [0][-]{section*.56}{TiCC\040PhD\040Series}{}% 90
