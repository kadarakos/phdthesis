\BOOKMARK [0][-]{section*.1}{Acknowledgements}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{General\040introduction}{chapter.1}% 3
\BOOKMARK [2][-]{subsection.1.1.1}{Learning\040representations}{section.1.1}% 4
\BOOKMARK [2][-]{subsection.1.1.2}{Learning\040representations\040of\040words}{section.1.1}% 5
\BOOKMARK [2][-]{subsection.1.1.3}{Visually\040grounded\040word\040representations}{section.1.1}% 6
\BOOKMARK [2][-]{subsection.1.1.4}{Visually\040grounded\040sentence\040representations}{section.1.1}% 7
\BOOKMARK [2][-]{subsection.1.1.5}{Visual\040modality\040briding\040between\040languages}{section.1.1}% 8
\BOOKMARK [1][-]{section.1.2}{Background:\040Distributed\040linguistic\040representations}{chapter.1}% 9
\BOOKMARK [1][-]{section.1.3}{Grounded\040and\040multilingual\040representations}{chapter.1}% 10
\BOOKMARK [1][-]{section.1.4}{Distributed\040word-representations}{chapter.1}% 11
\BOOKMARK [2][-]{subsection.1.4.1}{Count-based\040approaches}{section.1.4}% 12
\BOOKMARK [2][-]{subsection.1.4.2}{Prediction-based\040approaches}{section.1.4}% 13
\BOOKMARK [3][-]{section*.4}{Neural\040language\040models}{subsection.1.4.2}% 14
\BOOKMARK [3][-]{equation.1.4.3}{Efficient\040linear\040models}{subsection.1.4.2}% 15
\BOOKMARK [1][-]{section.1.5}{Visually\040grounded\040representations\040of\040words}{chapter.1}% 16
\BOOKMARK [2][-]{subsection.1.5.1}{Language\040and\040perception}{section.1.5}% 17
\BOOKMARK [2][-]{subsection.1.5.2}{Combined\040distributional\040and\040visual\040spaces}{section.1.5}% 18
\BOOKMARK [1][-]{section.1.6}{From\040words\040to\040sentences}{chapter.1}% 19
\BOOKMARK [1][-]{section.1.7}{Visually\040grounded\040sentence\040representations}{chapter.1}% 20
\BOOKMARK [1][-]{section.1.8}{Visually\040grounded\040multilingual\040representations}{chapter.1}% 21
\BOOKMARK [2][-]{subsection.1.8.1}{Bilingual\040lexicon\040induction}{section.1.8}% 22
\BOOKMARK [2][-]{subsection.1.8.2}{Image\040pivots\040for\040translation}{section.1.8}% 23
\BOOKMARK [2][-]{subsection.1.8.3}{Multi-view\040perspective}{section.1.8}% 24
\BOOKMARK [1][-]{section.1.9}{Interpreting\040continuous\040representations}{chapter.1}% 25
\BOOKMARK [1][-]{section.1.10}{Published\040work}{chapter.1}% 26
\BOOKMARK [2][-]{subsection.1.10.1}{Chapters}{section.1.10}% 27
\BOOKMARK [2][-]{subsection.1.10.2}{Other\040publications\040completed\040during\040my\040PhD}{section.1.10}% 28
\BOOKMARK [0][-]{chapter.2}{Learning\040word\040meanings\040from\040images\040of\040natural\040scenes}{}% 29
\BOOKMARK [1][-]{section.2.1}{Introduction}{chapter.2}% 30
\BOOKMARK [2][-]{subsection.2.1.1}{Cross-situational\040learning}{section.2.1}% 31
\BOOKMARK [2][-]{subsection.2.1.2}{Learning\040meanings\040from\040images}{section.2.1}% 32
\BOOKMARK [2][-]{subsection.2.1.3}{Our\040study}{section.2.1}% 33
\BOOKMARK [1][-]{section.2.2}{Word\040learning\040model}{chapter.2}% 34
\BOOKMARK [2][-]{subsection.2.2.1}{Visual\040input}{section.2.2}% 35
\BOOKMARK [2][-]{subsection.2.2.2}{Learning\040algorithm}{section.2.2}% 36
\BOOKMARK [2][-]{subsection.2.2.3}{Baseline\040models}{section.2.2}% 37
\BOOKMARK [1][-]{section.2.3}{Experiments}{chapter.2}% 38
\BOOKMARK [2][-]{subsection.2.3.1}{Image\040datasets}{section.2.3}% 39
\BOOKMARK [2][-]{subsection.2.3.2}{Word\040similarity\040experiments}{section.2.3}% 40
\BOOKMARK [2][-]{subsection.2.3.3}{Effect\040of\040concreteness\040on\040similarity\040judgments}{section.2.3}% 41
\BOOKMARK [2][-]{subsection.2.3.4}{Word\040production}{section.2.3}% 42
\BOOKMARK [3][-]{section*.8}{Multi-word\040image\040descriptions.}{subsection.2.3.4}% 43
\BOOKMARK [3][-]{figure.caption.9}{Single-concept\040image\040descriptions}{subsection.2.3.4}% 44
\BOOKMARK [1][-]{section.2.4}{Results}{chapter.2}% 45
\BOOKMARK [2][-]{subsection.2.4.1}{Word\040similarity}{section.2.4}% 46
\BOOKMARK [3][-]{table.caption.12}{Concreteness}{subsection.2.4.1}% 47
\BOOKMARK [2][-]{subsection.2.4.2}{Word\040production}{section.2.4}% 48
\BOOKMARK [3][-]{section*.15}{Multi-word\040image\040descriptors}{subsection.2.4.2}% 49
\BOOKMARK [3][-]{table.caption.16}{Single-concept\040image\040descriptors}{subsection.2.4.2}% 50
\BOOKMARK [1][-]{section.2.5}{Discussion\040and\040conclusion}{chapter.2}% 51
\BOOKMARK [0][-]{chapter.3}{Representation\040of\040linguistic\040form\040and\040function\040in\040recurrent\040neural\040networks}{}% 52
\BOOKMARK [1][-]{section.3.1}{Introduction}{chapter.3}% 53
\BOOKMARK [1][-]{section.3.2}{Related\040work}{chapter.3}% 54
\BOOKMARK [1][-]{section.3.3}{Models}{chapter.3}% 55
\BOOKMARK [2][-]{subsection.3.3.1}{Gated\040Recurrent\040Neural\040Networks}{section.3.3}% 56
\BOOKMARK [2][-]{subsection.3.3.2}{Imaginet}{section.3.3}% 57
\BOOKMARK [2][-]{subsection.3.3.3}{Unimodal\040language\040model}{section.3.3}% 58
\BOOKMARK [2][-]{subsection.3.3.4}{Sum\040of\040word\040embeddings}{section.3.3}% 59
\BOOKMARK [1][-]{section.3.4}{Experiments}{chapter.3}% 60
\BOOKMARK [2][-]{subsection.3.4.1}{Computing\040Omission\040Scores}{section.3.4}% 61
\BOOKMARK [2][-]{subsection.3.4.2}{Omission\040score\040distributions}{section.3.4}% 62
\BOOKMARK [2][-]{subsection.3.4.3}{Beyond\040Lexical\040Cues}{section.3.4}% 63
\BOOKMARK [3][-]{figure.caption.25}{Sensitivity\040to\040grammatical\040function}{subsection.3.4.3}% 64
\BOOKMARK [3][-]{figure.caption.26}{Sensitivity\040to\040linear\040structure}{subsection.3.4.3}% 65
\BOOKMARK [2][-]{subsection.3.4.4}{Lexical\040versus\040abstract\040contexts}{section.3.4}% 66
\BOOKMARK [1][-]{section.3.5}{Discussion}{chapter.3}% 67
\BOOKMARK [2][-]{subsection.3.5.1}{Generalizing\040to\040other\040architectures}{section.3.5}% 68
\BOOKMARK [2][-]{subsection.3.5.2}{Future\040directions}{section.3.5}% 69
\BOOKMARK [0][-]{chapter.4}{Imagination\040Improves\040Multimodal\040Translation}{}% 70
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 71
\BOOKMARK [1][-]{section.4.2}{Problem\040Formulation}{chapter.4}% 72
\BOOKMARK [1][-]{section.4.3}{Imagination\040Model}{chapter.4}% 73
\BOOKMARK [2][-]{subsection.4.3.1}{Shared\040Encoder}{section.4.3}% 74
\BOOKMARK [2][-]{subsection.4.3.2}{Neural\040Machine\040Translation\040Decoder}{section.4.3}% 75
\BOOKMARK [2][-]{subsection.4.3.3}{Imaginet\040Decoder}{section.4.3}% 76
\BOOKMARK [1][-]{section.4.4}{Data}{chapter.4}% 77
\BOOKMARK [1][-]{section.4.5}{Experiments}{chapter.4}% 78
\BOOKMARK [2][-]{subsection.4.5.1}{Hyperparameters}{section.4.5}% 79
\BOOKMARK [2][-]{subsection.4.5.2}{In-domain\040experiments}{section.4.5}% 80
\BOOKMARK [2][-]{subsection.4.5.3}{External\040described\040image\040data}{section.4.5}% 81
\BOOKMARK [2][-]{subsection.4.5.4}{External\040parallel\040text\040data}{section.4.5}% 82
\BOOKMARK [2][-]{subsection.4.5.5}{Ensemble\040results}{section.4.5}% 83
\BOOKMARK [2][-]{subsection.4.5.6}{Multi30K\0402017\040results}{section.4.5}% 84
\BOOKMARK [2][-]{subsection.4.5.7}{Qualitative\040examples}{section.4.5}% 85
\BOOKMARK [1][-]{section.4.6}{Discussion}{chapter.4}% 86
\BOOKMARK [2][-]{subsection.4.6.1}{Does\040the\040model\040learn\040grounded\040representations?}{section.4.6}% 87
\BOOKMARK [2][-]{subsection.4.6.2}{The\040effect\040of\040visual\040feature\040vectors}{section.4.6}% 88
\BOOKMARK [1][-]{section.4.7}{Related\040work}{chapter.4}% 89
\BOOKMARK [1][-]{section.4.8}{Conclusion}{chapter.4}% 90
\BOOKMARK [0][-]{chapter.5}{Lessons\040learned\040in\040multilingual\040grounded\040language\040learning}{}% 91
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 92
\BOOKMARK [1][-]{section.5.2}{Related\040work}{chapter.5}% 93
\BOOKMARK [1][-]{section.5.3}{Multilingual\040grounded\040learning}{chapter.5}% 94
\BOOKMARK [1][-]{section.5.4}{Experimental\040setup}{chapter.5}% 95
\BOOKMARK [1][-]{section.5.5}{Bilingual\040Experiments}{chapter.5}% 96
\BOOKMARK [2][-]{subsection.5.5.1}{Reproducing\040gella2017image}{section.5.5}% 97
\BOOKMARK [2][-]{subsection.5.5.2}{Translations\040vs.\040independent\040captions}{section.5.5}% 98
\BOOKMARK [2][-]{subsection.5.5.3}{Overlapping\040vs.\040non-overlapping\040images}{section.5.5}% 99
\BOOKMARK [1][-]{section.5.6}{Multilingual\040experiments}{chapter.5}% 100
\BOOKMARK [2][-]{subsection.5.6.1}{Translation\040vs.\040independent\040captions}{section.5.6}% 101
\BOOKMARK [2][-]{subsection.5.6.2}{High-to-low\040resource\040transfer}{section.5.6}% 102
\BOOKMARK [2][-]{subsection.5.6.3}{Bilingual\040vs.\040multilingual}{section.5.6}% 103
\BOOKMARK [1][-]{section.5.7}{Conclusions}{chapter.5}% 104
\BOOKMARK [0][-]{chapter.6}{Revisiting\040the\040Hierarchical\040Multiscale\040LSTM}{}% 105
\BOOKMARK [1][-]{section.6.1}{Pre-amble}{chapter.6}% 106
\BOOKMARK [1][-]{section.6.2}{Introduction}{chapter.6}% 107
\BOOKMARK [2][-]{subsection.6.2.1}{The\040importance\040of\040reproducibility}{section.6.2}% 108
\BOOKMARK [2][-]{subsection.6.2.2}{The\040importance\040of\040interpretability}{section.6.2}% 109
\BOOKMARK [1][-]{section.6.3}{Hierarchical\040Multiscale\040LSTM}{chapter.6}% 110
\BOOKMARK [1][-]{section.6.4}{Experiments}{chapter.6}% 111
\BOOKMARK [2][-]{subsection.6.4.1}{Experimental\040setup}{section.6.4}% 112
\BOOKMARK [2][-]{subsection.6.4.2}{Ablation\040factors}{section.6.4}% 113
\BOOKMARK [1][-]{section.6.5}{Experimental\040Results}{chapter.6}% 114
\BOOKMARK [2][-]{subsection.6.5.1}{Reproducing\040language\040modeling\040results}{section.6.5}% 115
\BOOKMARK [2][-]{subsection.6.5.2}{Ablation\040results}{section.6.5}% 116
\BOOKMARK [2][-]{subsection.6.5.3}{Segmentation\040results}{section.6.5}% 117
\BOOKMARK [1][-]{section.6.6}{Conclusion}{chapter.6}% 118
\BOOKMARK [1][-]{section.Alph0.1}{Vectorized\040formulation\040of\040the\040HMLSTM}{chapter.6}% 119
\BOOKMARK [1][-]{section.Alph0.2}{Vectorized\040formulation\040of\040the\040HMRNN}{chapter.6}% 120
\BOOKMARK [0][-]{appendix.A}{General\040discussion\040and\040conclusion}{}% 121
\BOOKMARK [0][-]{section*.62}{Summary}{}% 122
\BOOKMARK [0][-]{section*.64}{Publication\040list}{}% 123
\BOOKMARK [0][-]{section*.66}{References}{}% 124
\BOOKMARK [0][-]{section*.68}{TiCC\040PhD\040Series}{}% 125
