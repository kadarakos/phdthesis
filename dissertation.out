\BOOKMARK [0][-]{section*.1}{Acknowledgements}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Learning\040representations}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Learning\040representations\040of\040words}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.3}{Visually\040grounded\040word\040representations}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{Visually\040grounded\040sentence\040representations}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.5}{Visual\040modality\040bridging\040between\040languages}{chapter.1}% 7
\BOOKMARK [1][-]{section.1.6}{Published\040work}{chapter.1}% 8
\BOOKMARK [2][-]{subsection.1.6.1}{Chapters}{section.1.6}% 9
\BOOKMARK [2][-]{subsection.1.6.2}{Publications\040completed\040during\040the\040PhD}{section.1.6}% 10
\BOOKMARK [3][-]{section*.4}{Publications\040on\040Vision\040and\040Language}{subsection.1.6.2}% 11
\BOOKMARK [3][-]{section*.4}{Publications\040on\040other\040topics}{subsection.1.6.2}% 12
\BOOKMARK [0][-]{chapter.2}{Background}{}% 13
\BOOKMARK [1][-]{section.2.1}{Distributed\040word-representations}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.1.1}{Count-based\040approaches}{section.2.1}% 15
\BOOKMARK [2][-]{subsection.2.1.2}{Prediction-based\040approaches}{section.2.1}% 16
\BOOKMARK [3][-]{section*.5}{Neural\040language\040models}{subsection.2.1.2}% 17
\BOOKMARK [3][-]{equation.2.1.2}{Efficient\040linear\040models}{subsection.2.1.2}% 18
\BOOKMARK [1][-]{section.2.2}{Visually\040grounded\040representations\040of\040words}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.2.1}{Language\040and\040perception}{section.2.2}% 20
\BOOKMARK [2][-]{subsection.2.2.2}{Combined\040distributional\040and\040visual\040spaces}{section.2.2}% 21
\BOOKMARK [1][-]{section.2.3}{From\040words\040to\040sentences}{chapter.2}% 22
\BOOKMARK [1][-]{section.2.4}{Neural\040sentence\040representations}{chapter.2}% 23
\BOOKMARK [1][-]{section.2.5}{Visually\040grounded\040sentence\040representations}{chapter.2}% 24
\BOOKMARK [1][-]{section.2.6}{Visually\040grounded\040multilingual\040representations}{chapter.2}% 25
\BOOKMARK [2][-]{subsection.2.6.1}{Multi-view\040representation\040learning\040perspective}{section.2.6}% 26
\BOOKMARK [2][-]{subsection.2.6.2}{Images\040as\040pivots\040for\040translation}{section.2.6}% 27
\BOOKMARK [1][-]{section.2.7}{Interpreting\040continuous\040representations}{chapter.2}% 28
\BOOKMARK [0][-]{chapter.3}{Learning\040word\040meanings\040from\040images\040of\040natural\040scenes}{}% 29
\BOOKMARK [1][-]{section.3.1}{Introduction}{chapter.3}% 30
\BOOKMARK [2][-]{subsection.3.1.1}{Cross-situational\040learning}{section.3.1}% 31
\BOOKMARK [2][-]{subsection.3.1.2}{Learning\040meanings\040from\040images}{section.3.1}% 32
\BOOKMARK [2][-]{subsection.3.1.3}{Our\040study}{section.3.1}% 33
\BOOKMARK [1][-]{section.3.2}{Word\040learning\040model}{chapter.3}% 34
\BOOKMARK [2][-]{subsection.3.2.1}{Visual\040input}{section.3.2}% 35
\BOOKMARK [2][-]{subsection.3.2.2}{Learning\040algorithm}{section.3.2}% 36
\BOOKMARK [2][-]{subsection.3.2.3}{Baseline\040models}{section.3.2}% 37
\BOOKMARK [1][-]{section.3.3}{Experiments}{chapter.3}% 38
\BOOKMARK [2][-]{subsection.3.3.1}{Image\040datasets}{section.3.3}% 39
\BOOKMARK [2][-]{subsection.3.3.2}{Word\040similarity\040experiments}{section.3.3}% 40
\BOOKMARK [2][-]{subsection.3.3.3}{Effect\040of\040concreteness\040on\040similarity\040judgments}{section.3.3}% 41
\BOOKMARK [2][-]{subsection.3.3.4}{Word\040production}{section.3.3}% 42
\BOOKMARK [3][-]{section*.9}{Multi-word\040image\040descriptions.}{subsection.3.3.4}% 43
\BOOKMARK [3][-]{figure.caption.10}{Single-concept\040image\040descriptions}{subsection.3.3.4}% 44
\BOOKMARK [1][-]{section.3.4}{Results}{chapter.3}% 45
\BOOKMARK [2][-]{subsection.3.4.1}{Word\040similarity}{section.3.4}% 46
\BOOKMARK [3][-]{table.caption.13}{Concreteness}{subsection.3.4.1}% 47
\BOOKMARK [2][-]{subsection.3.4.2}{Word\040production}{section.3.4}% 48
\BOOKMARK [3][-]{section*.16}{Multi-word\040image\040descriptors}{subsection.3.4.2}% 49
\BOOKMARK [3][-]{table.caption.17}{Single-concept\040image\040descriptors}{subsection.3.4.2}% 50
\BOOKMARK [1][-]{section.3.5}{Discussion\040and\040conclusion}{chapter.3}% 51
\BOOKMARK [0][-]{chapter.4}{Representation\040of\040linguistic\040form\040and\040function\040in\040recurrent\040neural\040networks}{}% 52
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 53
\BOOKMARK [1][-]{section.4.2}{Related\040work}{chapter.4}% 54
\BOOKMARK [1][-]{section.4.3}{Models}{chapter.4}% 55
\BOOKMARK [2][-]{subsection.4.3.1}{Gated\040Recurrent\040Neural\040Networks}{section.4.3}% 56
\BOOKMARK [2][-]{subsection.4.3.2}{Imaginet}{section.4.3}% 57
\BOOKMARK [2][-]{subsection.4.3.3}{Unimodal\040language\040model}{section.4.3}% 58
\BOOKMARK [2][-]{subsection.4.3.4}{Sum\040of\040word\040embeddings}{section.4.3}% 59
\BOOKMARK [1][-]{section.4.4}{Experiments}{chapter.4}% 60
\BOOKMARK [2][-]{subsection.4.4.1}{Computing\040Omission\040Scores}{section.4.4}% 61
\BOOKMARK [2][-]{subsection.4.4.2}{Omission\040score\040distributions}{section.4.4}% 62
\BOOKMARK [2][-]{subsection.4.4.3}{Beyond\040Lexical\040Cues}{section.4.4}% 63
\BOOKMARK [3][-]{figure.caption.26}{Sensitivity\040to\040grammatical\040function}{subsection.4.4.3}% 64
\BOOKMARK [3][-]{figure.caption.27}{Sensitivity\040to\040linear\040structure}{subsection.4.4.3}% 65
\BOOKMARK [2][-]{subsection.4.4.4}{Lexical\040versus\040abstract\040contexts}{section.4.4}% 66
\BOOKMARK [1][-]{section.4.5}{Discussion}{chapter.4}% 67
\BOOKMARK [2][-]{subsection.4.5.1}{Generalizing\040to\040other\040architectures}{section.4.5}% 68
\BOOKMARK [2][-]{subsection.4.5.2}{Future\040directions}{section.4.5}% 69
\BOOKMARK [0][-]{chapter.5}{Imagination\040Improves\040Multimodal\040Translation}{}% 70
\BOOKMARK [1][-]{section.5.1}{Introduction}{chapter.5}% 71
\BOOKMARK [1][-]{section.5.2}{Problem\040Formulation}{chapter.5}% 72
\BOOKMARK [1][-]{section.5.3}{Imagination\040Model}{chapter.5}% 73
\BOOKMARK [2][-]{subsection.5.3.1}{Shared\040Encoder}{section.5.3}% 74
\BOOKMARK [2][-]{subsection.5.3.2}{Neural\040Machine\040Translation\040Decoder}{section.5.3}% 75
\BOOKMARK [2][-]{subsection.5.3.3}{Imaginet\040Decoder}{section.5.3}% 76
\BOOKMARK [1][-]{section.5.4}{Data}{chapter.5}% 77
\BOOKMARK [1][-]{section.5.5}{Experiments}{chapter.5}% 78
\BOOKMARK [2][-]{subsection.5.5.1}{Hyperparameters}{section.5.5}% 79
\BOOKMARK [2][-]{subsection.5.5.2}{In-domain\040experiments}{section.5.5}% 80
\BOOKMARK [2][-]{subsection.5.5.3}{External\040described\040image\040data}{section.5.5}% 81
\BOOKMARK [2][-]{subsection.5.5.4}{External\040parallel\040text\040data}{section.5.5}% 82
\BOOKMARK [2][-]{subsection.5.5.5}{Ensemble\040results}{section.5.5}% 83
\BOOKMARK [2][-]{subsection.5.5.6}{Multi30K\0402017\040results}{section.5.5}% 84
\BOOKMARK [2][-]{subsection.5.5.7}{Qualitative\040examples}{section.5.5}% 85
\BOOKMARK [1][-]{section.5.6}{Discussion}{chapter.5}% 86
\BOOKMARK [2][-]{subsection.5.6.1}{Does\040the\040model\040learn\040grounded\040representations?}{section.5.6}% 87
\BOOKMARK [2][-]{subsection.5.6.2}{The\040effect\040of\040visual\040feature\040vectors}{section.5.6}% 88
\BOOKMARK [1][-]{section.5.7}{Related\040work}{chapter.5}% 89
\BOOKMARK [1][-]{section.5.8}{Conclusion}{chapter.5}% 90
\BOOKMARK [0][-]{chapter.6}{Lessons\040learned\040in\040multilingual\040grounded\040language\040learning}{}% 91
\BOOKMARK [1][-]{section.6.1}{Introduction}{chapter.6}% 92
\BOOKMARK [1][-]{section.6.2}{Related\040work}{chapter.6}% 93
\BOOKMARK [1][-]{section.6.3}{Multilingual\040grounded\040learning}{chapter.6}% 94
\BOOKMARK [1][-]{section.6.4}{Experimental\040setup}{chapter.6}% 95
\BOOKMARK [1][-]{section.6.5}{Bilingual\040Experiments}{chapter.6}% 96
\BOOKMARK [2][-]{subsection.6.5.1}{Reproducing\040gella2017image}{section.6.5}% 97
\BOOKMARK [2][-]{subsection.6.5.2}{Translations\040vs.\040independent\040captions}{section.6.5}% 98
\BOOKMARK [2][-]{subsection.6.5.3}{Overlapping\040vs.\040non-overlapping\040images}{section.6.5}% 99
\BOOKMARK [1][-]{section.6.6}{Multilingual\040experiments}{chapter.6}% 100
\BOOKMARK [2][-]{subsection.6.6.1}{Translation\040vs.\040independent\040captions}{section.6.6}% 101
\BOOKMARK [2][-]{