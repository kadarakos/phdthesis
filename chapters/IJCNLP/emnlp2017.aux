\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Specia2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Imagination Improves Multimodal Translation}{95}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:IJCNLP}{{4}{95}{Imagination Improves Multimodal Translation}{chapter.4}{}}
\@writefile{toc}{\contentsline {paragraph}{abstract}{95}{chapter.4}}
\citation{Specia2016}
\citation{Bahdanau2015}
\citation{Chrupala2015}
\citation{Kadar2016}
\citation{Chrupala2015}
\citation{Hodosh2013}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{96}{section.4.1}}
\citation{ElliottFrankSimaanSpecia2016}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The Imagination model learns visually-grounded representations by sharing the encoder network between the Translation Decoder with image prediction in the {\sc  imaginet} Decoder.\relax }}{97}{figure.caption.39}}
\newlabel{fig:model}{{4.1}{97}{The Imagination model learns visually-grounded representations by sharing the encoder network between the Translation Decoder with image prediction in the {\sc imaginet} Decoder.\relax }{figure.caption.39}{}}
\citation{Chen2015}
\citation{Tiedemann2012}
\citation{Specia2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Problem Formulation}{99}{section.4.2}}
\newlabel{sec:problem}{{4.2}{99}{Problem Formulation}{section.4.2}{}}
\citation{Luong2016}
\citation{Schuster1997}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Imagination Model}{100}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Shared Encoder}{100}{subsection.4.3.1}}
\newlabel{sec:model:encoder}{{4.3.1}{100}{Shared Encoder}{subsection.4.3.1}{}}
\citation{Bahdanau2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Neural Machine Translation Decoder}{101}{subsection.4.3.2}}
\newlabel{eqn:decoder_init}{{4.8}{101}{Neural Machine Translation Decoder}{equation.4.3.8}{}}
\citation{Chrupala2015}
\citation{Vendrov2016,Chrupala2017}
\citation{ElliottFrankSimaanSpecia2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Imaginet Decoder}{103}{subsection.4.3.3}}
\newlabel{eqn:imaginet}{{4.15}{103}{Imaginet Decoder}{equation.4.3.15}{}}
\citation{Sennrich2014}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces The datasets used in our experiments.\relax }}{104}{table.caption.40}}
\newlabel{tab:datasets}{{4.1}{104}{The datasets used in our experiments.\relax }{table.caption.40}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Data}{104}{section.4.4}}
\newlabel{sec:data}{{4.4}{104}{Data}{section.4.4}{}}
\citation{Chen2015}
\citation{Tiedemann2012}
\citation{Schuster2012}
\citation{Szegedy2015}
\citation{denkowski:lavie:meteor-wmt:2014}
\citation{Papineni:2002:BMA:1073083.1073135}
\citation{Cho2014}
\citation{Sennrich2017}
\citation{Kingma2015}
\citation{Gal2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Experiments}{105}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Hyperparameters}{105}{subsection.4.5.1}}
\citation{Calixto2017c}
\citation{Calixto2017b}
\citation{toyama2016neural}
\citation{Hitschler2016}
\citation{Koehn2007}
\citation{Specia2016}
\citation{Calixto2017c}
\citation{Calixto2017b}
\citation{Hitschler2016}
\citation{toyama2016neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}In-domain experiments}{106}{subsection.4.5.2}}
\newlabel{sec:in_domain_all}{{4.5.2}{106}{In-domain experiments}{subsection.4.5.2}{}}
\citation{toyama2016neural}
\citation{Calixto2017c}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces En$\rightarrow $De translation results on the Multi30K dataset. Our Imagination model is competitive with the state of the art when it is trained on in-domain data. We report the mean and standard deviation of three random initialisations.\relax }}{107}{table.caption.41}}
\newlabel{tab:results:in-domain}{{4.2}{107}{En$\rightarrow $De translation results on the Multi30K dataset. Our Imagination model is competitive with the state of the art when it is trained on in-domain data. We report the mean and standard deviation of three random initialisations.\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}External described image data}{107}{subsection.4.5.3}}
\newlabel{sec:experiments:ood-images}{{4.5.3}{107}{External described image data}{subsection.4.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Translation results when using out-of-domain described images. Our approach is still effective when the image prediction model is trained over the COCO dataset.\relax }}{108}{table.caption.42}}
\newlabel{tab:results:ood-coco}{{4.3}{108}{Translation results when using out-of-domain described images. Our approach is still effective when the image prediction model is trained over the COCO dataset.\relax }{table.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Translation results with out-of-domain parallel text and described images. We find further improvements when we multitask with the News Commentary (NC) and COCO datasets.\relax }}{108}{table.caption.43}}
\newlabel{tab:results:ood-both}{{4.4}{108}{Translation results with out-of-domain parallel text and described images. We find further improvements when we multitask with the News Commentary (NC) and COCO datasets.\relax }{table.caption.43}{}}
\citation{Freitag2016}
\citation{Calixto2017c}
\citation{Sennrich2016b}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Ensemble decoding results. Zmorge denotes models trained with decompounded German words; Sub-word denotes joint SentencePiece word splitting (see Section \ref  {sec:data} for more details).\relax }}{109}{table.caption.44}}
\newlabel{tab:results:ensemble}{{4.5}{109}{Ensemble decoding results. Zmorge denotes models trained with decompounded German words; Sub-word denotes joint SentencePiece word splitting (see Section \ref {sec:data} for more details).\relax }{table.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}External parallel text data}{109}{subsection.4.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Ensemble results}{110}{subsection.4.5.5}}
\citation{Elliott2017}
\citation{Elliott2017}
\citation{Graham2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Examples where our model improves or worsens the translation compared to the NMT baseline. Top: NMT translates the wrong body part; both models skip ``pipe''. Middle: NMT incorrectly translates the verb and misses several nouns. Bottom: Our model incorrectly translates the preposition.\relax }}{111}{table.caption.45}}
\newlabel{tab:results:examples}{{4.6}{111}{Examples where our model improves or worsens the translation compared to the NMT baseline. Top: NMT translates the wrong body part; both models skip ``pipe''. Middle: NMT incorrectly translates the verb and misses several nouns. Bottom: Our model incorrectly translates the preposition.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.6}Multi30K 2017 results}{111}{subsection.4.5.6}}
\citation{Klejch2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.7}Qualitative examples}{112}{subsection.4.5.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Discussion}{112}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Does the model learn grounded representations?}{112}{subsection.4.6.1}}
\citation{Jabri2016,Kiela2016}
\citation{Simonyan2015}
\citation{Szegedy2015}
\citation{He2016}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces We can interpret the {\sc  imaginet} Decoder by visualising the predictions made by our model.\relax }}{113}{figure.caption.46}}
\newlabel{fig:discussion:examples}{{4.2}{113}{We can interpret the {\sc imaginet} Decoder by visualising the predictions made by our model.\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}The effect of visual feature vectors}{113}{subsection.4.6.2}}
\citation{Szegedy2015}
\citation{ElliottFrankHasler2015,Huang2016}
\citation{Libovicky2016}
\citation{Shah2016,Hitschler2016}
\citation{Calixto2016,Caglayan2016b,Calixto2017c}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces The type of visual features predicted by the {\sc  imaginet} Decoder has a strong impact on the Multitask model performance.\relax }}{114}{table.caption.47}}
\newlabel{tab:results:features}{{4.7}{114}{The type of visual features predicted by the {\sc imaginet} Decoder has a strong impact on the Multitask model performance.\relax }{table.caption.47}{}}
\citation{toyama2016neural}
\citation{Saha2016}
\citation{Nakayama2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Related work}{115}{section.4.7}}
\citation{Caruana1997}
\citation{Klerke2016}
\citation{Plank2016}
\citation{Bingel2017}
\citation{Dong2015}
\citation{Firat2016}
\citation{Luong2016}
\citation{Lin2015}
\citation{Chrupala2015}
\citation{Gelderloos2016}
\citation{Collell2017}
\citation{Srivastava2015}
\citation{Pasunuru2017}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Conclusion}{117}{section.4.8}}
\@setckpt{chapters/IJCNLP/emnlp2017}{
\setcounter{page}{119}
\setcounter{equation}{15}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{5}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{2}
\setcounter{table}{7}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{18}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{82}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{8}
\setcounter{section@level}{0}
}
