\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Specia2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Imagination Improves Multimodal Translation}{109}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:IJCNLP}{{4}{109}{Imagination Improves Multimodal Translation}{chapter.4}{}}
\@writefile{toc}{\contentsline {paragraph}{abstract}{109}{chapter.4}}
\citation{Specia2016}
\citation{Bahdanau2015}
\citation{Chrupala2015}
\citation{Kadar2016}
\citation{Chrupala2015}
\citation{Hodosh2013}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{110}{section.4.1}}
\citation{ElliottFrankSimaanSpecia2016}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The Imagination model learns visually-grounded representations by sharing the encoder network between the Translation Decoder with image prediction in the {\sc  imaginet} Decoder.\relax }}{111}{figure.caption.31}}
\newlabel{fig:model}{{4.1}{111}{The Imagination model learns visually-grounded representations by sharing the encoder network between the Translation Decoder with image prediction in the {\sc imaginet} Decoder.\relax }{figure.caption.31}{}}
\citation{Chen2015}
\citation{Tiedemann2012}
\citation{Specia2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Problem Formulation}{113}{section.4.2}}
\newlabel{sec:problem}{{4.2}{113}{Problem Formulation}{section.4.2}{}}
\citation{Luong2016}
\citation{Schuster1997}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Imagination Model}{114}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Shared Encoder}{114}{subsection.4.3.1}}
\newlabel{sec:model:encoder}{{4.3.1}{114}{Shared Encoder}{subsection.4.3.1}{}}
\citation{Bahdanau2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Neural Machine Translation Decoder}{115}{subsection.4.3.2}}
\newlabel{eqn:decoder_init}{{4.8}{115}{Neural Machine Translation Decoder}{equation.4.3.8}{}}
\citation{Chrupala2015}
\citation{Vendrov2016,Chrupala2017}
\citation{ElliottFrankSimaanSpecia2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Imaginet Decoder}{117}{subsection.4.3.3}}
\newlabel{eqn:imaginet}{{4.15}{117}{Imaginet Decoder}{equation.4.3.15}{}}
\citation{Sennrich2014}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces The datasets used in our experiments.\relax }}{118}{table.caption.32}}
\newlabel{tab:datasets}{{4.1}{118}{The datasets used in our experiments.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Data}{118}{section.4.4}}
\newlabel{sec:data}{{4.4}{118}{Data}{section.4.4}{}}
\citation{Chen2015}
\citation{Tiedemann2012}
\citation{Schuster2012}
\citation{Szegedy2015}
\citation{denkowski:lavie:meteor-wmt:2014}
\citation{Papineni:2002:BMA:1073083.1073135}
\citation{Cho2014}
\citation{Sennrich2017}
\citation{Kingma2015}
\citation{Gal2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Experiments}{119}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Hyperparameters}{119}{subsection.4.5.1}}
\citation{Calixto2017c}
\citation{Calixto2017b}
\citation{toyama2016neural}
\citation{Hitschler2016}
\citation{Koehn2007}
\citation{Specia2016}
\citation{Calixto2017c}
\citation{Calixto2017b}
\citation{Hitschler2016}
\citation{toyama2016neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}In-domain experiments}{120}{subsection.4.5.2}}
\newlabel{sec:in_domain_all}{{4.5.2}{120}{In-domain experiments}{subsection.4.5.2}{}}
\citation{toyama2016neural}
\citation{Calixto2017c}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces En$\rightarrow $De translation results on the Multi30K dataset. Our Imagination model is competitive with the state of the art when it is trained on in-domain data. We report the mean and standard deviation of three random initialisations.\relax }}{121}{table.caption.33}}
\newlabel{tab:results:in-domain}{{4.2}{121}{En$\rightarrow $De translation results on the Multi30K dataset. Our Imagination model is competitive with the state of the art when it is trained on in-domain data. We report the mean and standard deviation of three random initialisations.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}External described image data}{121}{subsection.4.5.3}}
\newlabel{sec:experiments:ood-images}{{4.5.3}{121}{External described image data}{subsection.4.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Translation results when using out-of-domain described images. Our approach is still effective when the image prediction model is trained over the COCO dataset.\relax }}{122}{table.caption.34}}
\newlabel{tab:results:ood-coco}{{4.3}{122}{Translation results when using out-of-domain described images. Our approach is still effective when the image prediction model is trained over the COCO dataset.\relax }{table.caption.34}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Translation results with out-of-domain parallel text and described images. We find further improvements when we multitask with the News Commentary (NC) and COCO datasets.\relax }}{122}{table.caption.35}}
\newlabel{tab:results:ood-both}{{4.4}{122}{Translation results with out-of-domain parallel text and described images. We find further improvements when we multitask with the News Commentary (NC) and COCO datasets.\relax }{table.caption.35}{}}
\citation{Freitag2016}
\citation{Calixto2017c}
\citation{Sennrich2016b}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Ensemble decoding results. Zmorge denotes models trained with decompounded German words; Sub-word denotes joint SentencePiece word splitting (see Section \ref  {sec:data} for more details).\relax }}{123}{table.caption.36}}
\newlabel{tab:results:ensemble}{{4.5}{123}{Ensemble decoding results. Zmorge denotes models trained with decompounded German words; Sub-word denotes joint SentencePiece word splitting (see Section \ref {sec:data} for more details).\relax }{table.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}External parallel text data}{123}{subsection.4.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Ensemble results}{124}{subsection.4.5.5}}
\citation{Elliott2017}
\citation{Elliott2017}
\citation{Graham2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Examples where our model improves or worsens the translation compared to the NMT baseline. Top: NMT translates the wrong body part; both models skip ``pipe''. Middle: NMT incorrectly translates the verb and misses several nouns. Bottom: Our model incorrectly translates the preposition.\relax }}{125}{table.caption.37}}
\newlabel{tab:results:examples}{{4.6}{125}{Examples where our model improves or worsens the translation compared to the NMT baseline. Top: NMT translates the wrong body part; both models skip ``pipe''. Middle: NMT incorrectly translates the verb and misses several nouns. Bottom: Our model incorrectly translates the preposition.\relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.6}Multi30K 2017 results}{125}{subsection.4.5.6}}
\citation{Klejch2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.7}Qualitative examples}{126}{subsection.4.5.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Discussion}{126}{section.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Does the model learn grounded representations?}{126}{subsection.4.6.1}}
\citation{Jabri2016,Kiela2016}
\citation{Simonyan2015}
\citation{Szegedy2015}
\citation{He2016}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces We can interpret the {\sc  imaginet} Decoder by visualising the predictions made by our model.\relax }}{127}{figure.caption.38}}
\newlabel{fig:discussion:examples}{{4.2}{127}{We can interpret the {\sc imaginet} Decoder by visualising the predictions made by our model.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}The effect of visual feature vectors}{127}{subsection.4.6.2}}
\citation{Szegedy2015}
\citation{ElliottFrankHasler2015,Huang2016}
\citation{Libovicky2016}
\citation{Shah2016,Hitschler2016}
\citation{Calixto2016,Caglayan2016b,Calixto2017c}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces The type of visual features predicted by the {\sc  imaginet} Decoder has a strong impact on the Multitask model performance.\relax }}{128}{table.caption.39}}
\newlabel{tab:results:features}{{4.7}{128}{The type of visual features predicted by the {\sc imaginet} Decoder has a strong impact on the Multitask model performance.\relax }{table.caption.39}{}}
\citation{toyama2016neural}
\citation{Saha2016}
\citation{Nakayama2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Related work}{129}{section.4.7}}
\citation{Caruana1997}
\citation{Klerke2016}
\citation{Plank2016}
\citation{Bingel2017}
\citation{Dong2015}
\citation{Firat2016}
\citation{Luong2016}
\citation{Lin2015}
\citation{Chrupala2015}
\citation{Gelderloos2016}
\citation{Collell2017}
\citation{Srivastava2015}
\citation{Pasunuru2017}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Conclusion}{131}{section.4.8}}
\@setckpt{chapters/IJCNLP/emnlp2017}{
\setcounter{page}{133}
\setcounter{equation}{15}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{5}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{2}
\setcounter{table}{7}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{19}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{90}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{section@level}{0}
}
