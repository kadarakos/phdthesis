\section{Data}\label{sec:data}

\begin{table}
\renewcommand{\arraystretch}{1.3}
\centering
\begin{tabular}{ccccc}
\toprule
& Size & Tokens & Types & Images\\
\midrule
\multicolumn{5}{l}{Multi30K: parallel text with images}\\
En & \multirow{2}{*}{31K} & 377K & 10K & \multirow{2}{*}{31K}\\
De & & 368K & 16K & \\
\midrule
\multicolumn{5}{l}{MS COCO: external described images}\\
En    & 414K & 4.3M & 24K & 83K \\
\midrule
\multicolumn{5}{l}{News Commentary: external parallel text}\\
En   & \multirow{2}{*}{240K} & 8.31M & \multirow{2}{*}{17K} &  --\\
De   & & 8.95M & & --\\
\bottomrule
\end{tabular}
\caption{The datasets used in our experiments.}\label{tab:datasets}
\end{table}

We evaluate our model using the benchmark Multi30K dataset \cite{ElliottFrankSimaanSpecia2016}, which is the largest collection of images paired with sentences in multiple languages. This dataset contains 31,014 images paired with an English language sentence and a German language translation: 29,000 instances are reserved for training, 1,014 for development, and 1,000 for evaluation.\footnote{The Multi30K dataset also contains 155K independently collected descriptions in German and English. In order to make our experiments more comparable with previous work, we do not make use of this data.}

The English and German sentences are preprocessed by normalising the punctuation, lowercasing and tokenizing the text using the Moses toolkit. We additionally decompound the German text  using Zmorge \cite{Sennrich2014}. This results in vocabulary sizes of 10,214 types for English and 16,022 for German.

We also use two external datasets to evaluate our model: the MS COCO dataset of English described images \cite{Chen2015}, and the English-German News Commentary parallel corpus \cite{Tiedemann2012}. When we perform experiments with the News Commentary corpus, we first calculate a 17,597 sub-word vocabulary using SentencePiece \cite{Schuster2012} over the concatentation of the Multi30K and News Commentary datasets. This gives us a shared vocabulary for the external data that reduces the number of out-of-vocabulary tokens. 

Images are represented by 2048D vectors extracted from the `pool5/7x7\_s1' layer of the GoogLeNet v3 CNN \cite{Szegedy2015}.