\subsection{Characteristics of the Pseudopairs}


We now investigate the properties of the pseudopairs generated by our method. In particular, we focus on pseudpairs generated by an aligned plus disjoint model (En+De+COCO+c2c) and a disjoint model (De+COCO).

The pseudopairs generated by the \textit{aligned plus disjoint} model cover 40\% of the German captions in the M30K data set, and overall, the pseudopairs form a heavy-tailed distribution.
%is not uniform, it is Zipfian \cite{zipf1949human}. Figure \ref{fig:annotation_freq} shows the distribution of transferred annotations against their rank on a log-log scale: 150 captions are used to annotate 20\% of the data. 
We find a similar pattern for the pseudopairs generated by the \textit{disjoint} model: the pseudopairs cover 37\% of the M30K data set, and the top 150 captions cover 23\% of the data. This is far from using each caption equally in the pseudopair transfer, and may suggest a hubness problem \citep{dinu2014improving}. We assessed the stability of the sets of transferred captions using the Jaccard measure in two cases: (i) different random seeds, and (ii) disjoint or aligned plus disjoint. For the \emph{aligned plus disjoint} model, we observe an overlap of 0.53 between different random seeds compared to 0.51 for the \emph{disjoint} model. The overlap between the two types of models is much lower at 0.41. Finally, we find that when a caption is transferred by both models, the overlap of the caption annotating the same COCO image is 0.33 for the \emph{disjoint} model, and 0.34 for the \emph{aligned plus disjoint} model, and the overlap between the models is 0.16. This shows that the models do not transfer the same captions for the same images.

%\begin{figure}[t]
%    \centering
%    \includegraphics[width=0.4\textwidth]{assets/annotation_freq.pdf}
%    \caption{Frequency distribution of the German captions transferred by the \textit{disjoint plus aligned} model.}
%    \label{fig:annotation_freq}
%\end{figure}

Figure \ref{fig:pseudopairs} presents examples of the annotations transferred using the pseudopair method. The first example demonstrates the difference between the Multi30K and COCO datasets: there are no giraffes in the former, but there are dogs (``Hund'').  In the second example, both captions imply that the man sits \emph{on} the tree not beside it. This shows that even if the datasets are similar, transferring a caption that exactly matches the picture is difficult. The final two examples show semantically accurate and similar sentences are transferred by both models. In the fourth example, both models transfer exactly the same caption.




\input{chapters/EMNLP2/figure-pseudopairs}


%To gain some insight into the general characteristics of the pseudopair sets we investigate the ones generated by the \emph{aligned plus disjont} (En+De+COCO+c2c) and \emph{disjoint} (De+COCO) models. 

\begin{comment}
First note that M30K training set only contains 145K
captions while that of COCO has 566435 meaning 
that if all captions would be
used they would be repeated \~4 times on average.
However, the pseudopairs generated by the 
\emph{aligned plus disjont} model only
consist of \~40\% of the German captions available 
in M30K, which means that
the same captions are re-used on average 11 times.
Taking a closer look at the frequency distribution, however,  
reveals that only a few sentences are used: 
the 150 most common captions cover approximately 
20\%  of the full data.
For the \emph{disjoint} model we find similar trends:
the pseudopairs make up a slightly smaller 
37\% of the captions in M30K and the top 150 captions have
a slightly higher 23\% coverage.

Since at most 40\% of the M30K training captions are used 
in the pseudopair sets we assess how \emph{stable} 
these subsets are across random seeds and between models. 
We use the Jaccard 
coefficient to measure overlap. 
For the \emph{aligned plus disjoint} 
model we find a slightly higher overlap of
0.53 compared to the 0.51 of the \emph{disjoint} model. 
The overlap between the \emph{aligned plus disjoint} and 
\emph{disjoint} models is much lower at 0.41.
We also compare for each caption that is in both the considered 
pseudopair sets how likely that they were
retrieved for the same sentence in COCO. Within \emph{disjoint} this is 0.33, within \emph{aligned plus disjoint} 
its 0.34 and between the two its 0.16. 

Finally let us take a closer look at some of the 
pseudopair examples in
Figure~\ref{fig:pseudopairs}. For the first 3 pictures 
in the top row
both models retrieve semantically similar captions, however, none of them are 
exactly adequate. The first picture demonstrates the domain-shift problem as 
there are no giraffes in M30K, but there are dogs.
On the second picture both models retrieve a caption saying that the man 
sits \emph{on} the tree not 
besides. This is an example of a case where even if the domains overlap, 
finding a caption that exactly
matches the picture might be unlikely. The sixth picture shows the same 
phenomena where \emph{surfer}
and \emph{parachute} are reasonable guesses, but not quite right. On the 8th 
picture we see an example
where the both models retrieve something about a \emph{sign}, but both captions 
are completely missleading. Examples 4, 5 and 7 are instances of perfect matches.
\end{comment}

%The pseudo-pair data set generated by the same model without the caption--caption loss
%has very similar characteristics. It uses approximately 39\% of the M30K German captions
%and the 150 most common captions also cover 20\% of the pseudo-pair set. 
%However, we find
%that the c2c pseudo-pairs cover a larger vocabulary: using the same pre-processing scheme
%to compute the vocabulary as in the experiments the average vocabulary-size 
%across three random seeds of the 
%c2c pseudo-pairs is 12679.3, while without the c2c objective it is only 12626 
%The average overlap between the generated pseudo-pairs across all three seeds
%for both models with and without c2c is 0.53 (jaccard coefficient). The overlap 
%between the the models considering all 6 seed pairs is 0.46.