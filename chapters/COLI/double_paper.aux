\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Representation of linguistic form and function in recurrent neural networks}{57}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:COLI}{{3}{57}{Representation of linguistic form and function in recurrent neural networks}{chapter.3}{}}
\@writefile{toc}{\contentsline {paragraph}{abstract}{57}{chapter.3}}
\citation{elman1990finding}
\citation{vinyals2015grammar}
\citation{bahdanau2014neural}
\citation{gregor2015draw}
\citation{visin2015reseg}
\citation{karpathy2015deep}
\citation{yu2015video}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{58}{section.3.1}}
\newlabel{sec:intro}{{3.1}{58}{Introduction}{section.3.1}{}}
\citation{chrupala2015learning}
\citation{cho2014properties,chung2014empirical}
\citation{elman1991distributed,karpathy2015visualizing}
\newlabel{explainimaginet}{{3.1}{59}{Introduction}{section.3.1}{}}
\citation{elman1990finding}
\citation{jordan1986attractor}
\citation{elman1991distributed}
\citation{giles1992extracting}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Related work}{60}{section.3.2}}
\newlabel{sec:related}{{3.2}{60}{Related work}{section.3.2}{}}
\citation{li2015visualizing}
\citation{hochreiter1997long}
\citation{bahdanau2014neural}
\citation{rocktaschel2016reasoning}
\citation{karpathy2015visualizing}
\citation{li2015convergent}
\citation{krizhevsky2012imagenet}
\citation{erhan2009visualizing,simonyan2013deep,yosinski2015understanding,nguyen2016multifaceted}
\citation{mahendran2015visualizing,dosovitskiy2015inverting}
\newlabel{edit:attention}{{3.2}{62}{Related work}{section.3.2}{}}
\citation{li2016understanding}
\citation{adi2016fine}
\citation{linzen2016assessing}
\citation{simonyan2013deep,yosinski2015understanding,mahendran2015understanding}
\citation{eigen2013understanding}
\citation{zhou2014object}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Models}{64}{section.3.3}}
\citation{chrupala2015learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Gated Recurrent Neural Networks}{65}{subsection.3.3.1}}
\newlabel{sec:gru}{{3.3.1}{65}{Gated Recurrent Neural Networks}{subsection.3.3.1}{}}
\newlabel{eq:gru-update}{{3.2}{65}{Gated Recurrent Neural Networks}{equation.3.3.2}{}}
\newlabel{eq:gru-cand}{{3.3}{65}{Gated Recurrent Neural Networks}{equation.3.3.3}{}}
\newlabel{eq:gru-reset}{{3.4}{65}{Gated Recurrent Neural Networks}{equation.3.3.4}{}}
\citation{chrupala2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Structure of {\sc  Imaginet}, adapted from \cite {chrupala2015learning}.\relax }}{66}{figure.caption.24}}
\newlabel{fig:imaginet}{{3.1}{66}{Structure of {\sc Imaginet}, adapted from \protect \cite {chrupala2015learning}.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Imaginet}{66}{subsection.3.3.2}}
\newlabel{sec:imaginet}{{3.3.2}{66}{Imaginet}{subsection.3.3.2}{}}
\citation{simonyan2014very}
\citation{chrupala2015learning}
\citation{chrupala2015learning}
\newlabel{eq:losscombo}{{3.11}{67}{Imaginet}{equation.3.3.11}{}}
\newlabel{edit:dumdumeddy}{{\TextOrMath  {\textasteriskcentered }{*}}{67}{}{Hfootnote.10}{}}
\newlabel{ft:imaginet}{{\TextOrMath  {\textdagger }{\dagger }}{67}{}{Hfootnote.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Unimodal language model}{68}{subsection.3.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Sum of word embeddings}{68}{subsection.3.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Experiments}{68}{section.3.4}}
\newlabel{sec:experiments}{{3.4}{68}{Experiments}{section.3.4}{}}
\citation{lin2014microsoft}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Computing Omission Scores}{69}{subsection.3.4.1}}
\newlabel{sec:computeomission}{{3.4.1}{69}{Computing Omission Scores}{subsection.3.4.1}{}}
\newlabel{edit:whyposdep}{{3.4.1}{69}{Computing Omission Scores}{subsection.3.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Omission scores for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} for {\sc  LM} and the two pathways, {\sc  Textual} and {\sc  Visual}, of {\sc  Imaginet.}\relax }}{70}{figure.caption.25}}
\newlabel{fig:omissionex}{{3.2}{70}{Omission scores for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} for {\sc LM} and the two pathways, {\sc Textual} and {\sc Visual}, of {\sc Imaginet.}\relax }{figure.caption.25}{}}
\newlabel{eg:omit}{{3.12}{70}{Computing Omission Scores}{equation.3.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Images retrieved for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }}{71}{figure.caption.26}}
\newlabel{fig:omissionexpic}{{3.3}{71}{Images retrieved for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }{figure.caption.26}{}}
\newlabel{edit:retrievalexplain}{{3.4.1}{71}{Computing Omission Scores}{equation.3.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Omission score distributions}{71}{subsection.3.4.2}}
\newlabel{sec:omitimaginet}{{3.4.2}{71}{Omission score distributions}{subsection.3.4.2}{}}
\newlabel{subsec:omission-text-vis}{{3.4.2}{71}{Omission score distributions}{subsection.3.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc  Textual} and {\sc  Visual} pathways and for {\sc  LM}. Only labels which occur at least 1250 times are included.\relax }}{72}{figure.caption.27}}
\newlabel{fig:omission-imaginet}{{3.4}{72}{Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc Textual} and {\sc Visual} pathways and for {\sc LM}. Only labels which occur at least 1250 times are included.\relax }{figure.caption.27}{}}
\newlabel{ft:boxplots}{{\TextOrMath  {\textsection }{\mathsection }}{72}{}{Hfootnote.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Distributions of log ratios of omission scores of {\sc  Textual} to {\sc  Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{73}{figure.caption.28}}
\newlabel{fig:omission-imaginet-ratio}{{3.5}{73}{Distributions of log ratios of omission scores of {\sc Textual} to {\sc Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.28}{}}
\newlabel{edit:textualomission}{{3.4.2}{73}{Omission score distributions}{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Distributions of log ratios of omission scores of {\sc  LM} to {\sc  Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{75}{figure.caption.29}}
\newlabel{fig:omission-imaginet-quotient}{{3.6}{75}{Distributions of log ratios of omission scores of {\sc LM} to {\sc Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Beyond Lexical Cues}{75}{subsection.3.4.3}}
\newlabel{sec:beyondlexical}{{3.4.3}{75}{Beyond Lexical Cues}{subsection.3.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Proportion of variance in omission scores explained by linear regression.\relax }}{76}{table.caption.30}}
\newlabel{tab:lr-r2}{{3.1}{76}{Proportion of variance in omission scores explained by linear regression.\relax }{table.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Proportion of variance in omission scores explained by the linear regression models for {\sc  Sum}, {\sc  LM}, {\sc  Visual} and {\sc  Textual}, relative to regressing on word identity and position only. \relax }}{78}{figure.caption.31}}
\newlabel{fig:rsquared}{{3.7}{78}{Proportion of variance in omission scores explained by the linear regression models for {\sc Sum}, {\sc LM}, {\sc Visual} and {\sc Textual}, relative to regressing on word identity and position only. \relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to grammatical function}{78}{figure.caption.31}}
\newlabel{sec:gramfunc}{{3.4.3}{78}{Sensitivity to grammatical function}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Distribution of omission scores per dependency label for the selected word types.\relax }}{79}{figure.caption.32}}
\newlabel{fig:top_words}{{3.8}{79}{Distribution of omission scores per dependency label for the selected word types.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Coefficients on the y-axis of {\sc  LR full} corresponding to the position variables on the x-axis.\relax }}{80}{figure.caption.33}}
\newlabel{fig:posrqs}{{3.9}{80}{Coefficients on the y-axis of {\sc LR full} corresponding to the position variables on the x-axis.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to linear structure}{80}{figure.caption.32}}
\newlabel{subsec:information-struct}{{3.4.3}{80}{Sensitivity to linear structure}{figure.caption.32}{}}
\citation{karpathy2015visualizing,li2015convergent}
\newlabel{edit:topiccomment}{{3.4.3}{81}{Sensitivity to linear structure}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Lexical versus abstract contexts}{81}{subsection.3.4.4}}
\newlabel{sec:contexts}{{3.4.4}{81}{Lexical versus abstract contexts}{subsection.3.4.4}{}}
\citation{li2015convergent}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Distributions of the mutual information scores for the three networks and the six context types.\relax }}{83}{figure.caption.34}}
\newlabel{fig:raw_mutual}{{3.10}{83}{Distributions of the mutual information scores for the three networks and the six context types.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc  Textual} vs {\sc  Visual}; right: {\sc  LM} vs {\sc  Textual}\relax }}{84}{figure.caption.35}}
\newlabel{fig:mi-boot}{{3.11}{84}{Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc Textual} vs {\sc Visual}; right: {\sc LM} vs {\sc Textual}\relax }{figure.caption.35}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }}{85}{table.caption.36}}
\newlabel{tab:mi-examples}{{3.2}{85}{Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }{table.caption.36}{}}
\citation{kai2015treelstm}
\citation{yoonneural2014}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Discussion}{86}{section.3.5}}
\newlabel{sec:conclusion}{{3.5}{86}{Discussion}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Generalizing to other architectures}{86}{subsection.3.5.1}}
\newlabel{edit:omitgeneral}{{3.5.1}{86}{Generalizing to other architectures}{subsection.3.5.1}{}}
\citation{sutskever2014sequence}
\citation{kiros2015skip}
\citation{bahdanau2014neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Future directions}{87}{subsection.3.5.2}}
\newlabel{edit:humanjudgement}{{3.5.2}{87}{Future directions}{subsection.3.5.2}{}}
\@setckpt{chapters/COLI/double_paper}{
\setcounter{page}{89}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{4}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{2}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{13}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{17}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{9}
\setcounter{section@level}{0}
}
