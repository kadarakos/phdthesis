\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Representation of linguistic form and function in recurrent neural networks}{51}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{abstract}{51}{chapter.3}}
\citation{elman1990finding}
\citation{vinyals2015grammar}
\citation{bahdanau2014neural}
\citation{gregor2015draw}
\citation{visin2015reseg}
\citation{karpathy2015deep}
\citation{yu2015video}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{52}{section.3.1}}
\newlabel{sec:intro}{{3.1}{52}{Introduction}{section.3.1}{}}
\citation{chrupala2015learning}
\citation{cho2014properties,chung2014empirical}
\citation{elman1991distributed,karpathy2015visualizing}
\newlabel{explainimaginet}{{3.1}{53}{Introduction}{section.3.1}{}}
\citation{elman1990finding}
\citation{jordan1986attractor}
\citation{elman1991distributed}
\citation{giles1992extracting}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Related work}{54}{section.3.2}}
\newlabel{sec:related}{{3.2}{54}{Related work}{section.3.2}{}}
\citation{li2015visualizing}
\citation{hochreiter1997long}
\citation{bahdanau2014neural}
\citation{rocktaschel2016reasoning}
\citation{karpathy2015visualizing}
\citation{li2015convergent}
\citation{krizhevsky2012imagenet}
\citation{erhan2009visualizing,simonyan2013deep,yosinski2015understanding,nguyen2016multifaceted}
\citation{mahendran2015visualizing,dosovitskiy2015inverting}
\newlabel{edit:attention}{{3.2}{56}{Related work}{section.3.2}{}}
\citation{li2016understanding}
\citation{adi2016fine}
\citation{linzen2016assessing}
\citation{simonyan2013deep,yosinski2015understanding,mahendran2015understanding}
\citation{eigen2013understanding}
\citation{zhou2014object}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Models}{58}{section.3.3}}
\citation{chrupala2015learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Gated Recurrent Neural Networks}{59}{subsection.3.3.1}}
\newlabel{sec:gru}{{3.3.1}{59}{Gated Recurrent Neural Networks}{subsection.3.3.1}{}}
\newlabel{eq:gru-update}{{3.2}{59}{Gated Recurrent Neural Networks}{equation.3.3.2}{}}
\newlabel{eq:gru-cand}{{3.3}{59}{Gated Recurrent Neural Networks}{equation.3.3.3}{}}
\newlabel{eq:gru-reset}{{3.4}{59}{Gated Recurrent Neural Networks}{equation.3.3.4}{}}
\citation{chrupala2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Structure of {\sc  Imaginet}, adapted from \cite {chrupala2015learning}.\relax }}{60}{figure.caption.15}}
\newlabel{fig:imaginet}{{3.1}{60}{Structure of {\sc Imaginet}, adapted from \protect \cite {chrupala2015learning}.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Imaginet}{60}{subsection.3.3.2}}
\newlabel{sec:imaginet}{{3.3.2}{60}{Imaginet}{subsection.3.3.2}{}}
\citation{simonyan2014very}
\citation{chrupala2015learning}
\citation{chrupala2015learning}
\newlabel{eq:losscombo}{{3.11}{61}{Imaginet}{equation.3.3.11}{}}
\newlabel{edit:dumdumeddy}{{\TextOrMath  {\textasteriskcentered }{*}}{61}{}{Hfootnote.10}{}}
\newlabel{ft:imaginet}{{\TextOrMath  {\textdagger }{\dagger }}{61}{}{Hfootnote.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Unimodal language model}{62}{subsection.3.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Sum of word embeddings}{62}{subsection.3.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Experiments}{62}{section.3.4}}
\newlabel{sec:experiments}{{3.4}{62}{Experiments}{section.3.4}{}}
\citation{lin2014microsoft}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Computing Omission Scores}{63}{subsection.3.4.1}}
\newlabel{sec:computeomission}{{3.4.1}{63}{Computing Omission Scores}{subsection.3.4.1}{}}
\newlabel{edit:whyposdep}{{3.4.1}{63}{Computing Omission Scores}{subsection.3.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Omission scores for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} for {\sc  LM} and the two pathways, {\sc  Textual} and {\sc  Visual}, of {\sc  Imaginet.}\relax }}{64}{figure.caption.16}}
\newlabel{fig:omissionex}{{3.2}{64}{Omission scores for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} for {\sc LM} and the two pathways, {\sc Textual} and {\sc Visual}, of {\sc Imaginet.}\relax }{figure.caption.16}{}}
\newlabel{eg:omit}{{3.12}{64}{Computing Omission Scores}{equation.3.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Images retrieved for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }}{65}{figure.caption.17}}
\newlabel{fig:omissionexpic}{{3.3}{65}{Images retrieved for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }{figure.caption.17}{}}
\newlabel{edit:retrievalexplain}{{3.4.1}{65}{Computing Omission Scores}{equation.3.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Omission score distributions}{65}{subsection.3.4.2}}
\newlabel{sec:omitimaginet}{{3.4.2}{65}{Omission score distributions}{subsection.3.4.2}{}}
\newlabel{subsec:omission-text-vis}{{3.4.2}{65}{Omission score distributions}{subsection.3.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc  Textual} and {\sc  Visual} pathways and for {\sc  LM}. Only labels which occur at least 1250 times are included.\relax }}{66}{figure.caption.18}}
\newlabel{fig:omission-imaginet}{{3.4}{66}{Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc Textual} and {\sc Visual} pathways and for {\sc LM}. Only labels which occur at least 1250 times are included.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Distributions of log ratios of omission scores of {\sc  Textual} to {\sc  Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{67}{figure.caption.19}}
\newlabel{fig:omission-imaginet-ratio}{{3.5}{67}{Distributions of log ratios of omission scores of {\sc Textual} to {\sc Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.19}{}}
\newlabel{edit:textualomission}{{3.4.2}{68}{Omission score distributions}{figure.caption.19}{}}
\newlabel{ft:boxplots}{{\TextOrMath  {\textsection }{\mathsection }}{68}{}{Hfootnote.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Distributions of log ratios of omission scores of {\sc  LM} to {\sc  Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{69}{figure.caption.20}}
\newlabel{fig:omission-imaginet-quotient}{{3.6}{69}{Distributions of log ratios of omission scores of {\sc LM} to {\sc Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Beyond Lexical Cues}{70}{subsection.3.4.3}}
\newlabel{sec:beyondlexical}{{3.4.3}{70}{Beyond Lexical Cues}{subsection.3.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Proportion of variance in omission scores explained by linear regression.\relax }}{71}{table.caption.21}}
\newlabel{tab:lr-r2}{{3.1}{71}{Proportion of variance in omission scores explained by linear regression.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to grammatical function}{72}{figure.caption.22}}
\newlabel{sec:gramfunc}{{3.4.3}{72}{Sensitivity to grammatical function}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Proportion of variance in omission scores explained by the linear regression models for {\sc  Sum}, {\sc  LM}, {\sc  Visual} and {\sc  Textual}, relative to regressing on word identity and position only. \relax }}{73}{figure.caption.22}}
\newlabel{fig:rsquared}{{3.7}{73}{Proportion of variance in omission scores explained by the linear regression models for {\sc Sum}, {\sc LM}, {\sc Visual} and {\sc Textual}, relative to regressing on word identity and position only. \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Distribution of omission scores per dependency label for the selected word types.\relax }}{74}{figure.caption.23}}
\newlabel{fig:top_words}{{3.8}{74}{Distribution of omission scores per dependency label for the selected word types.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Coefficients on the y-axis of {\sc  LR full} corresponding to the position variables on the x-axis.\relax }}{75}{figure.caption.24}}
\newlabel{fig:posrqs}{{3.9}{75}{Coefficients on the y-axis of {\sc LR full} corresponding to the position variables on the x-axis.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to linear structure}{75}{figure.caption.23}}
\newlabel{subsec:information-struct}{{3.4.3}{75}{Sensitivity to linear structure}{figure.caption.23}{}}
\citation{karpathy2015visualizing,li2015convergent}
\newlabel{edit:topiccomment}{{3.4.3}{76}{Sensitivity to linear structure}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Lexical versus abstract contexts}{76}{subsection.3.4.4}}
\newlabel{sec:contexts}{{3.4.4}{76}{Lexical versus abstract contexts}{subsection.3.4.4}{}}
\citation{li2015convergent}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Distributions of the mutual information scores for the three networks and the six context types.\relax }}{78}{figure.caption.25}}
\newlabel{fig:raw_mutual}{{3.10}{78}{Distributions of the mutual information scores for the three networks and the six context types.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc  Textual} vs {\sc  Visual}; right: {\sc  LM} vs {\sc  Textual}\relax }}{79}{figure.caption.26}}
\newlabel{fig:mi-boot}{{3.11}{79}{Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc Textual} vs {\sc Visual}; right: {\sc LM} vs {\sc Textual}\relax }{figure.caption.26}{}}
\citation{kai2015treelstm}
\citation{yoonneural2014}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Discussion}{80}{section.3.5}}
\newlabel{sec:conclusion}{{3.5}{80}{Discussion}{section.3.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }}{81}{table.caption.27}}
\newlabel{tab:mi-examples}{{3.2}{81}{Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }{table.caption.27}{}}
\citation{sutskever2014sequence}
\citation{kiros2015skip}
\citation{bahdanau2014neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Generalizing to other architectures}{82}{subsection.3.5.1}}
\newlabel{edit:omitgeneral}{{3.5.1}{82}{Generalizing to other architectures}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Future directions}{82}{subsection.3.5.2}}
\newlabel{edit:humanjudgement}{{3.5.2}{83}{Future directions}{subsection.3.5.2}{}}
\@setckpt{chapters/COLI/double_paper}{
\setcounter{page}{84}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{4}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{2}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{13}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{17}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{section@level}{0}
}
