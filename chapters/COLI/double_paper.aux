\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Representation of linguistic form and function in recurrent neural networks}{81}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:COLI}{{4}{81}{Representation of linguistic form and function in recurrent neural networks}{chapter.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Abstract}{81}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{This chapter is based on}{83}{section*.18}}
\citation{elman1990finding}
\citation{vinyals2015grammar}
\citation{Bahdanau2015}
\citation{gregor2015draw}
\citation{visin2015reseg}
\citation{karpathy2015deep}
\citation{yu2015video}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{84}{section.4.1}}
\newlabel{sec:intro}{{4.1}{84}{Introduction}{section.4.1}{}}
\citation{chrupala2015learning}
\citation{cho2014properties,chung2014empirical}
\citation{elman1991distributed,karpathy2015visualizing}
\newlabel{explainimaginet}{{4.1}{85}{Introduction}{section.4.1}{}}
\citation{elman1990finding}
\citation{jordan1986attractor}
\citation{elman1991distributed}
\citation{giles1992extracting}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Related work}{86}{section.4.2}}
\newlabel{sec:related}{{4.2}{86}{Related work}{section.4.2}{}}
\citation{li2015visualizing}
\citation{hochreiter1997long}
\citation{Bahdanau2015}
\citation{rocktaschel2016reasoning}
\newlabel{edit:attention}{{4.2}{87}{Related work}{section.4.2}{}}
\citation{karpathy2015visualizing}
\citation{li2015convergent}
\citation{krizhevsky2012imagenet}
\citation{erhan2009visualizing,simonyan2013deep,yosinski2015understanding,nguyen2016multifaceted}
\citation{mahendran2015visualizing,dosovitskiy2015inverting}
\citation{li2016understanding}
\citation{adi2016fine}
\citation{linzen2016assessing}
\citation{simonyan2013deep,yosinski2015understanding,mahendran2015understanding}
\citation{eigen2013understanding}
\citation{zhou2014object}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Models}{90}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Gated Recurrent Neural Networks}{90}{subsection.4.3.1}}
\newlabel{sec:gru}{{4.3.1}{90}{Gated Recurrent Neural Networks}{subsection.4.3.1}{}}
\citation{chrupala2015learning}
\citation{chrupala2015learning}
\newlabel{eq:gru-update}{{4.2}{91}{Gated Recurrent Neural Networks}{equation.4.3.2}{}}
\newlabel{eq:gru-cand}{{4.3}{91}{Gated Recurrent Neural Networks}{equation.4.3.3}{}}
\newlabel{eq:gru-reset}{{4.4}{91}{Gated Recurrent Neural Networks}{equation.4.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Imaginet}{91}{subsection.4.3.2}}
\newlabel{sec:imaginet}{{4.3.2}{91}{Imaginet}{subsection.4.3.2}{}}
\citation{simonyan2014very}
\citation{chrupala2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Structure of {\sc  Imaginet}, adapted from \cite {chrupala2015learning}.\relax }}{92}{figure.caption.19}}
\newlabel{fig:imaginet}{{4.1}{92}{Structure of {\sc Imaginet}, adapted from \protect \cite {chrupala2015learning}.\relax }{figure.caption.19}{}}
\newlabel{edit:dumdumeddy}{{1}{92}{}{Hfootnote.12}{}}
\citation{chrupala2015learning}
\newlabel{eq:losscombo}{{4.11}{93}{Imaginet}{equation.4.3.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Unimodal language model}{93}{subsection.4.3.3}}
\newlabel{ft:imaginet}{{2}{93}{}{Hfootnote.13}{}}
\citation{lin2014microsoft}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Sum of word embeddings}{94}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experiments}{94}{section.4.4}}
\newlabel{sec:experiments}{{4.4}{94}{Experiments}{section.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Omission scores for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} for {\sc  LM} and the two pathways, {\sc  Textual} and {\sc  Visual}, of {\sc  Imaginet.}\relax }}{95}{figure.caption.20}}
\newlabel{fig:omissionex}{{4.2}{95}{Omission scores for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} for {\sc LM} and the two pathways, {\sc Textual} and {\sc Visual}, of {\sc Imaginet.}\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Computing Omission Scores}{95}{subsection.4.4.1}}
\newlabel{sec:computeomission}{{4.4.1}{95}{Computing Omission Scores}{subsection.4.4.1}{}}
\newlabel{edit:whyposdep}{{4.4.1}{95}{Computing Omission Scores}{subsection.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Images retrieved for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }}{96}{figure.caption.21}}
\newlabel{fig:omissionexpic}{{4.3}{96}{Images retrieved for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }{figure.caption.21}{}}
\newlabel{eg:omit}{{4.12}{96}{Computing Omission Scores}{equation.4.4.12}{}}
\newlabel{edit:retrievalexplain}{{4.4.1}{97}{Computing Omission Scores}{equation.4.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Omission score distributions}{97}{subsection.4.4.2}}
\newlabel{sec:omitimaginet}{{4.4.2}{97}{Omission score distributions}{subsection.4.4.2}{}}
\newlabel{subsec:omission-text-vis}{{4.4.2}{97}{Omission score distributions}{subsection.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc  Textual} and {\sc  Visual} pathways and for {\sc  LM}. Only labels which occur at least 1250 times are included.\relax }}{97}{figure.caption.22}}
\newlabel{fig:omission-imaginet}{{4.4}{97}{Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc Textual} and {\sc Visual} pathways and for {\sc LM}. Only labels which occur at least 1250 times are included.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Distributions of log ratios of omission scores of {\sc  Textual} to {\sc  Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{98}{figure.caption.23}}
\newlabel{fig:omission-imaginet-ratio}{{4.5}{98}{Distributions of log ratios of omission scores of {\sc Textual} to {\sc Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.23}{}}
\newlabel{edit:textualomission}{{4.4.2}{99}{Omission score distributions}{figure.caption.23}{}}
\newlabel{ft:boxplots}{{4}{99}{}{Hfootnote.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Distributions of log ratios of omission scores of {\sc  LM} to {\sc  Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{100}{figure.caption.24}}
\newlabel{fig:omission-imaginet-quotient}{{4.6}{100}{Distributions of log ratios of omission scores of {\sc LM} to {\sc Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Beyond Lexical Cues}{101}{subsection.4.4.3}}
\newlabel{sec:beyondlexical}{{4.4.3}{101}{Beyond Lexical Cues}{subsection.4.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Proportion of variance in omission scores explained by linear regression.\relax }}{102}{table.caption.25}}
\newlabel{tab:lr-r2}{{4.1}{102}{Proportion of variance in omission scores explained by linear regression.\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3.1}Sensitivity to grammatical function}{103}{subsubsection.4.4.3.1}}
\newlabel{sec:gramfunc}{{4.4.3.1}{103}{Sensitivity to grammatical function}{subsubsection.4.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Proportion of variance in omission scores explained by the linear regression models for {\sc  Sum}, {\sc  LM}, {\sc  Visual} and {\sc  Textual}, relative to regressing on word identity and position only. \relax }}{104}{figure.caption.26}}
\newlabel{fig:rsquared}{{4.7}{104}{Proportion of variance in omission scores explained by the linear regression models for {\sc Sum}, {\sc LM}, {\sc Visual} and {\sc Textual}, relative to regressing on word identity and position only. \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Distribution of omission scores per dependency label for the selected word types.\relax }}{105}{figure.caption.27}}
\newlabel{fig:top_words}{{4.8}{105}{Distribution of omission scores per dependency label for the selected word types.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3.2}Sensitivity to linear structure}{105}{subsubsection.4.4.3.2}}
\newlabel{subsec:information-struct}{{4.4.3.2}{105}{Sensitivity to linear structure}{subsubsection.4.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Coefficients on the y-axis of {\sc  LR full} corresponding to the position variables on the x-axis.\relax }}{106}{figure.caption.28}}
\newlabel{fig:posrqs}{{4.9}{106}{Coefficients on the y-axis of {\sc LR full} corresponding to the position variables on the x-axis.\relax }{figure.caption.28}{}}
\newlabel{edit:topiccomment}{{4.4.3.2}{107}{Sensitivity to linear structure}{figure.caption.28}{}}
\citation{karpathy2015visualizing,li2015convergent}
\citation{li2015convergent}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Lexical versus abstract contexts}{108}{subsection.4.4.4}}
\newlabel{sec:contexts}{{4.4.4}{108}{Lexical versus abstract contexts}{subsection.4.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Distributions of the mutual information scores for the three networks and the six context types.\relax }}{109}{figure.caption.29}}
\newlabel{fig:raw_mutual}{{4.10}{109}{Distributions of the mutual information scores for the three networks and the six context types.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc  Textual} vs {\sc  Visual}; right: {\sc  LM} vs {\sc  Textual}\relax }}{110}{figure.caption.30}}
\newlabel{fig:mi-boot}{{4.11}{110}{Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc Textual} vs {\sc Visual}; right: {\sc LM} vs {\sc Textual}\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Discussion}{111}{section.4.5}}
\newlabel{sec:conclusion}{{4.5}{111}{Discussion}{section.4.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }}{112}{table.caption.31}}
\newlabel{tab:mi-examples}{{4.2}{112}{Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }{table.caption.31}{}}
\citation{kai2015treelstm}
\citation{yoonneural2014}
\citation{sutskever2014sequence}
\citation{kiros2015skip}
\citation{Bahdanau2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Generalizing to other architectures}{113}{subsection.4.5.1}}
\newlabel{edit:omitgeneral}{{4.5.1}{113}{Generalizing to other architectures}{subsection.4.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Future directions}{114}{subsection.4.5.2}}
\newlabel{edit:humanjudgement}{{4.5.2}{114}{Future directions}{subsection.4.5.2}{}}
\@setckpt{chapters/COLI/double_paper}{
\setcounter{page}{115}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{4}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{2}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{15}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{69}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{section@level}{2}
}
