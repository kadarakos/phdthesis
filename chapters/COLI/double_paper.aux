\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Representation of linguistic form and function in recurrent neural networks}{79}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:COLI}{{4}{79}{Representation of linguistic form and function in recurrent neural networks}{chapter.4}{}}
\@writefile{toc}{\contentsline {paragraph}{abstract}{79}{chapter.4}}
\citation{elman1990finding}
\citation{vinyals2015grammar}
\citation{bahdanau2014neural}
\citation{gregor2015draw}
\citation{visin2015reseg}
\citation{karpathy2015deep}
\citation{yu2015video}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{80}{section.4.1}}
\newlabel{sec:intro}{{4.1}{80}{Introduction}{section.4.1}{}}
\citation{chrupala2015learning}
\citation{cho2014properties,chung2014empirical}
\citation{elman1991distributed,karpathy2015visualizing}
\newlabel{explainimaginet}{{4.1}{81}{Introduction}{section.4.1}{}}
\citation{elman1990finding}
\citation{jordan1986attractor}
\citation{elman1991distributed}
\citation{giles1992extracting}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Related work}{82}{section.4.2}}
\newlabel{sec:related}{{4.2}{82}{Related work}{section.4.2}{}}
\citation{li2015visualizing}
\citation{hochreiter1997long}
\citation{bahdanau2014neural}
\citation{rocktaschel2016reasoning}
\citation{karpathy2015visualizing}
\citation{li2015convergent}
\citation{krizhevsky2012imagenet}
\citation{erhan2009visualizing,simonyan2013deep,yosinski2015understanding,nguyen2016multifaceted}
\citation{mahendran2015visualizing,dosovitskiy2015inverting}
\newlabel{edit:attention}{{4.2}{84}{Related work}{section.4.2}{}}
\citation{li2016understanding}
\citation{adi2016fine}
\citation{linzen2016assessing}
\citation{simonyan2013deep,yosinski2015understanding,mahendran2015understanding}
\citation{eigen2013understanding}
\citation{zhou2014object}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Models}{86}{section.4.3}}
\citation{chrupala2015learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Gated Recurrent Neural Networks}{87}{subsection.4.3.1}}
\newlabel{sec:gru}{{4.3.1}{87}{Gated Recurrent Neural Networks}{subsection.4.3.1}{}}
\newlabel{eq:gru-update}{{4.2}{87}{Gated Recurrent Neural Networks}{equation.4.3.2}{}}
\newlabel{eq:gru-cand}{{4.3}{87}{Gated Recurrent Neural Networks}{equation.4.3.3}{}}
\newlabel{eq:gru-reset}{{4.4}{87}{Gated Recurrent Neural Networks}{equation.4.3.4}{}}
\citation{chrupala2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Structure of {\sc  Imaginet}, adapted from \cite {chrupala2015learning}.\relax }}{88}{figure.caption.19}}
\newlabel{fig:imaginet}{{4.1}{88}{Structure of {\sc Imaginet}, adapted from \protect \cite {chrupala2015learning}.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Imaginet}{88}{subsection.4.3.2}}
\newlabel{sec:imaginet}{{4.3.2}{88}{Imaginet}{subsection.4.3.2}{}}
\citation{simonyan2014very}
\citation{chrupala2015learning}
\citation{chrupala2015learning}
\newlabel{eq:losscombo}{{4.11}{89}{Imaginet}{equation.4.3.11}{}}
\newlabel{edit:dumdumeddy}{{\TextOrMath  {\textasteriskcentered }{*}}{89}{}{Hfootnote.13}{}}
\newlabel{ft:imaginet}{{\TextOrMath  {\textdagger }{\dagger }}{89}{}{Hfootnote.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Unimodal language model}{90}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Sum of word embeddings}{90}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experiments}{90}{section.4.4}}
\newlabel{sec:experiments}{{4.4}{90}{Experiments}{section.4.4}{}}
\citation{lin2014microsoft}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Computing Omission Scores}{91}{subsection.4.4.1}}
\newlabel{sec:computeomission}{{4.4.1}{91}{Computing Omission Scores}{subsection.4.4.1}{}}
\newlabel{edit:whyposdep}{{4.4.1}{91}{Computing Omission Scores}{subsection.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Omission scores for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} for {\sc  LM} and the two pathways, {\sc  Textual} and {\sc  Visual}, of {\sc  Imaginet.}\relax }}{92}{figure.caption.20}}
\newlabel{fig:omissionex}{{4.2}{92}{Omission scores for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} for {\sc LM} and the two pathways, {\sc Textual} and {\sc Visual}, of {\sc Imaginet.}\relax }{figure.caption.20}{}}
\newlabel{eg:omit}{{4.12}{92}{Computing Omission Scores}{equation.4.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Images retrieved for the example sentence {\it  a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }}{93}{figure.caption.21}}
\newlabel{fig:omissionexpic}{{4.3}{93}{Images retrieved for the example sentence {\it a baby sits on a bed laughing with a laptop computer open} (left) and the same sentence with the second word omitted (right).\relax }{figure.caption.21}{}}
\newlabel{edit:retrievalexplain}{{4.4.1}{93}{Computing Omission Scores}{equation.4.4.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Omission score distributions}{93}{subsection.4.4.2}}
\newlabel{sec:omitimaginet}{{4.4.2}{93}{Omission score distributions}{subsection.4.4.2}{}}
\newlabel{subsec:omission-text-vis}{{4.4.2}{93}{Omission score distributions}{subsection.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc  Textual} and {\sc  Visual} pathways and for {\sc  LM}. Only labels which occur at least 1250 times are included.\relax }}{94}{figure.caption.22}}
\newlabel{fig:omission-imaginet}{{4.4}{94}{Distribution of omission scores for POS (left) and dependency labels (right), for the {\sc Textual} and {\sc Visual} pathways and for {\sc LM}. Only labels which occur at least 1250 times are included.\relax }{figure.caption.22}{}}
\newlabel{ft:boxplots}{{\TextOrMath  {\textsection }{\mathsection }}{94}{}{Hfootnote.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Distributions of log ratios of omission scores of {\sc  Textual} to {\sc  Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{95}{figure.caption.23}}
\newlabel{fig:omission-imaginet-ratio}{{4.5}{95}{Distributions of log ratios of omission scores of {\sc Textual} to {\sc Visual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.23}{}}
\newlabel{edit:textualomission}{{4.4.2}{95}{Omission score distributions}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Distributions of log ratios of omission scores of {\sc  LM} to {\sc  Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }}{97}{figure.caption.24}}
\newlabel{fig:omission-imaginet-quotient}{{4.6}{97}{Distributions of log ratios of omission scores of {\sc LM} to {\sc Textual} per POS (left) and dependency labels (right). Only labels which occur at least 1250 times are included.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Beyond Lexical Cues}{97}{subsection.4.4.3}}
\newlabel{sec:beyondlexical}{{4.4.3}{97}{Beyond Lexical Cues}{subsection.4.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Proportion of variance in omission scores explained by linear regression.\relax }}{98}{table.caption.25}}
\newlabel{tab:lr-r2}{{4.1}{98}{Proportion of variance in omission scores explained by linear regression.\relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Proportion of variance in omission scores explained by the linear regression models for {\sc  Sum}, {\sc  LM}, {\sc  Visual} and {\sc  Textual}, relative to regressing on word identity and position only. \relax }}{100}{figure.caption.26}}
\newlabel{fig:rsquared}{{4.7}{100}{Proportion of variance in omission scores explained by the linear regression models for {\sc Sum}, {\sc LM}, {\sc Visual} and {\sc Textual}, relative to regressing on word identity and position only. \relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to grammatical function}{100}{figure.caption.26}}
\newlabel{sec:gramfunc}{{4.4.3}{100}{Sensitivity to grammatical function}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Distribution of omission scores per dependency label for the selected word types.\relax }}{101}{figure.caption.27}}
\newlabel{fig:top_words}{{4.8}{101}{Distribution of omission scores per dependency label for the selected word types.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Coefficients on the y-axis of {\sc  LR full} corresponding to the position variables on the x-axis.\relax }}{102}{figure.caption.28}}
\newlabel{fig:posrqs}{{4.9}{102}{Coefficients on the y-axis of {\sc LR full} corresponding to the position variables on the x-axis.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sensitivity to linear structure}{102}{figure.caption.27}}
\newlabel{subsec:information-struct}{{4.4.3}{102}{Sensitivity to linear structure}{figure.caption.27}{}}
\citation{karpathy2015visualizing,li2015convergent}
\newlabel{edit:topiccomment}{{4.4.3}{103}{Sensitivity to linear structure}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Lexical versus abstract contexts}{103}{subsection.4.4.4}}
\newlabel{sec:contexts}{{4.4.4}{103}{Lexical versus abstract contexts}{subsection.4.4.4}{}}
\citation{li2015convergent}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Distributions of the mutual information scores for the three networks and the six context types.\relax }}{105}{figure.caption.29}}
\newlabel{fig:raw_mutual}{{4.10}{105}{Distributions of the mutual information scores for the three networks and the six context types.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc  Textual} vs {\sc  Visual}; right: {\sc  LM} vs {\sc  Textual}\relax }}{106}{figure.caption.30}}
\newlabel{fig:mi-boot}{{4.11}{106}{Bootstrap distributions of log ratios of median mutual information scores for word and dependency contexts. Left: {\sc Textual} vs {\sc Visual}; right: {\sc LM} vs {\sc Textual}\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }}{107}{table.caption.31}}
\newlabel{tab:mi-examples}{{4.2}{107}{Dimensions most strongly associated with the dependency trigram context type, and the top five contexts in which these dimensions have high values.\relax }{table.caption.31}{}}
\citation{kai2015treelstm}
\citation{yoonneural2014}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Discussion}{108}{section.4.5}}
\newlabel{sec:conclusion}{{4.5}{108}{Discussion}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Generalizing to other architectures}{108}{subsection.4.5.1}}
\newlabel{edit:omitgeneral}{{4.5.1}{108}{Generalizing to other architectures}{subsection.4.5.1}{}}
\citation{sutskever2014sequence}
\citation{kiros2015skip}
\citation{bahdanau2014neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Future directions}{109}{subsection.4.5.2}}
\newlabel{edit:humanjudgement}{{4.5.2}{109}{Future directions}{subsection.4.5.2}{}}
\@setckpt{chapters/COLI/double_paper}{
\setcounter{page}{111}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{4}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{5}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{2}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{18}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{16}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{69}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{section@level}{0}
}
