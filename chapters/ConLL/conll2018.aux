\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Lessons learned in multilingual grounded language learning}{123}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:ConLL}{{5}{123}{Lessons learned in multilingual grounded language learning}{chapter.5}{}}
\@writefile{toc}{\contentsline {paragraph}{abstract}{123}{chapter.5}}
\citation{barsalou2003grounding}
\citation{kiela2014improving,baroni2016grounding,elliott2017imagination,kiela2017learning,yoo2017improving}
\citation{dolan2004unsupervised,marelli2014sick,specia-EtAl:2016:WMT}
\citation{chung2016character}
\citation{ammar2016many}
\citation{gella2017image}
\citation{agirre2014semeval,agirre2015semeval}
\citation{barman2014code}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{124}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces An example taken from the {\it  Translation} and {\it  Comparable} portions of the Multi30K dataset. The translation portion (a) contains professional translations of the English captions into German, French, and Czech. The comparable portion (b) consists of five independently crowdsourced English and German descriptions, given only the image. Note that the sentences in (b) convey different information from the English--German translation pair in (a).\relax }}{125}{figure.caption.39}}
\newlabel{fig:data:example}{{5.1}{125}{An example taken from the {\it Translation} and {\it Comparable} portions of the Multi30K dataset. The translation portion (a) contains professional translations of the English captions into German, French, and Czech. The comparable portion (b) consists of five independently crowdsourced English and German descriptions, given only the image. Note that the sentences in (b) convey different information from the English--German translation pair in (a).\relax }{figure.caption.39}{}}
\citation{funaki2015image,rajendran2015bridge}
\citation{nakayama2017zero}
\citation{zoph2016transfer}
\citation{gella2017image}
\citation{finkelstein2001placing}
\citation{hill2015simlex}
\citation{kadar2015learning,bruni2014multimodal,kiela2014learning}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Related work}{127}{section.5.2}}
\citation{kiela2017learning,yoo2017improving}
\citation{kiros2015skip}
\citation{kiros2014unifying,karpathy2015deep}
\citation{mao2014deep,vinyals2015show,xu2015show}
\citation{antol2015vqa,fukui2016multimodal,jabri2016revisiting}
\citation{reed2016generative}
\citation{biblio732461325667051835,elliott2017imagination}
\citation{ammar2016many}
\citation{nivre2015universal}
\citation{johnson2016google}
\citation{lee2017fully}
\citation{peters2017massively}
\citation{ostling2016continuous}
\citation{malaviya2017learning}
\citation{gella2017image,calixto2017multilingual}
\citation{harwath2018vision}
\citation{kiros2014unifying,karpathy2015deep}
\citation{faghri2017vse++}
\citation{gella2017image}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Multilingual grounded learning}{130}{section.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Pseudo-code of the training procedure used to train our multilingual multi-task model.\relax }}{131}{figure.caption.40}}
\newlabel{fig:algo}{{5.2}{131}{Pseudo-code of the training procedure used to train our multilingual multi-task model.\relax }{figure.caption.40}{}}
\citation{faghri2017vse++}
\citation{he2016deep}
\citation{deng2009imagenet}
\citation{faghri2017vse++}
\citation{chung2014empirical}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {paragraph}{Implementation.}{132}{figure.caption.40}}
\citation{elliott2016multi30k,elliott2017findings}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Vocabulary overlap as measured by the Jaccard coefficient between the different languages on the translation portion of the Multi30K dataset.\relax }}{133}{table.caption.41}}
\newlabel{tab:data:vocab_overlap}{{5.1}{133}{Vocabulary overlap as measured by the Jaccard coefficient between the different languages on the translation portion of the Multi30K dataset.\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Experimental setup}{133}{section.5.4}}
\newlabel{sec:data}{{5.4}{133}{Experimental setup}{section.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Datasets.}{133}{table.caption.41}}
\citation{gella2017image}
\citation{gella2017image}
\citation{gella2017image}
\citation{gella2017image}
\citation{vendrov2015order}
\citation{gella2017image}
\@writefile{toc}{\contentsline {paragraph}{Evaluation.}{134}{table.caption.41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Bilingual Experiments}{134}{section.5.5}}
\newlabel{sec:bi}{{5.5}{134}{Bilingual Experiments}{section.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Reproducing \citet  {gella2017image}}{134}{subsection.5.5.1}}
\newlabel{sec:gella}{{5.5.1}{134}{Reproducing \citet {gella2017image}}{subsection.5.5.1}{}}
\citation{gella2017image}
\citation{faghri2017vse++}
\citation{gella2017image}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces English Image-to-text (I$\rightarrow $T) and text-to-image (T$\rightarrow $I) retrieval results on the \emph  {comparable} part of Multi30K, measured by Recall at 1, 5 at 10. {\tt  Typewriter} font shows performance of two sets of symmetric and asymmetric models from \citet  {gella2017image}.\relax }}{135}{table.caption.42}}
\newlabel{tab:bi:bilingualEng}{{5.2}{135}{English Image-to-text (I$\rightarrow $T) and text-to-image (T$\rightarrow $I) retrieval results on the \emph {comparable} part of Multi30K, measured by Recall at 1, 5 at 10. {\tt Typewriter} font shows performance of two sets of symmetric and asymmetric models from \citet {gella2017image}.\relax }{table.caption.42}{}}
\citation{gella2017image}
\citation{gella2017image}
\citation{gella2017image}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces German Image-to-text (I$\rightarrow $T) and text-to-image (T$\rightarrow $I) retrieval results on the \emph  {comparable} part of Multi30K, measured by Recall at 1, 5 at 10. {\tt  Typewriter} font shows performance of two sets of symmetric and asymmetric models from \citet  {gella2017image}.\relax }}{136}{table.caption.43}}
\newlabel{tab:bi:bilingualGer}{{5.3}{136}{German Image-to-text (I$\rightarrow $T) and text-to-image (T$\rightarrow $I) retrieval results on the \emph {comparable} part of Multi30K, measured by Recall at 1, 5 at 10. {\tt Typewriter} font shows performance of two sets of symmetric and asymmetric models from \citet {gella2017image}.\relax }{table.caption.43}{}}
\citation{gella2017image}
\citation{frank_elliott_specia_2018}
\newlabel{tab:bilingual}{{\caption@xref {tab:bilingual}{ on input line 122}}{137}{Translations vs.\ independent captions}{table.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces R@10 retrieval results on the \emph  {comparable} part of Multi30K. Bi-translation is trained on 29K \emph  {translation pair} data; bi-comparable is trained by downsampling the \emph  {comparable} data to 29K. \relax }}{137}{table.caption.44}}
\newlabel{tab:bitrans}{{5.4}{137}{R@10 retrieval results on the \emph {comparable} part of Multi30K. Bi-translation is trained on 29K \emph {translation pair} data; bi-comparable is trained by downsampling the \emph {comparable} data to 29K. \relax }{table.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Translations vs.\ independent captions}{137}{subsection.5.5.2}}
\newlabel{sec:bitrans}{{5.5.2}{137}{Translations vs.\ independent captions}{subsection.5.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Overlapping vs.\ non-overlapping images}{138}{subsection.5.5.3}}
\newlabel{sec:bioverlap}{{5.5.3}{138}{Overlapping vs.\ non-overlapping images}{subsection.5.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces R@10 retrieval results on the \emph  {comparable} part of Multi30K. Full model trained on the 29K images of the \emph  {comparable} part, Half model on 14.5K images using random downsampling. For Bi-overlap, both English and German captions are used for 14.5K images. For Bi-disjoint, 14.5K images are used for English and the remaining 14.5K images for German.\relax }}{139}{table.caption.45}}
\newlabel{tab:half}{{5.5}{139}{R@10 retrieval results on the \emph {comparable} part of Multi30K. Full model trained on the 29K images of the \emph {comparable} part, Half model on 14.5K images using random downsampling. For Bi-overlap, both English and German captions are used for 14.5K images. For Bi-disjoint, 14.5K images are used for English and the remaining 14.5K images for German.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Multilingual experiments}{140}{section.5.6}}
\newlabel{sec:multi}{{5.6}{140}{Multilingual experiments}{section.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Translation vs.\ independent captions}{141}{subsection.5.6.1}}
\newlabel{sec:multitrans}{{5.6.1}{141}{Translation vs.\ independent captions}{subsection.5.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}High-to-low resource transfer}{141}{subsection.5.6.2}}
\newlabel{sec:multitransfer}{{5.6.2}{141}{High-to-low resource transfer}{subsection.5.6.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces The Monolingual and joint Multi-translation models trained on \emph  {translation pairs}, and the Multi-comparable trained on the downsampled \emph  {comparable} set with one caption per image.\relax }}{142}{table.caption.46}}
\newlabel{tab:multilingual}{{5.6}{142}{The Monolingual and joint Multi-translation models trained on \emph {translation pairs}, and the Multi-comparable trained on the downsampled \emph {comparable} set with one caption per image.\relax }{table.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Bilingual vs. multilingual}{142}{subsection.5.6.3}}
\newlabel{sec:bivsmult}{{5.6.3}{142}{Bilingual vs. multilingual}{subsection.5.6.3}{}}
\citation{li2016adding}
\citation{P16-1168}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Multilingual is trained on all \emph  {translation pairs}, + Comparable adds the \emph  {comparable} data set.\relax }}{143}{table.caption.47}}
\newlabel{tab:multilingual-highlow}{{5.7}{143}{Multilingual is trained on all \emph {translation pairs}, + Comparable adds the \emph {comparable} data set.\relax }{table.caption.47}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Conclusions}{143}{section.5.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Comparing models from the Monolingual, Bilingual and Multilingual settings. The Monolingual and Bilingual models are trained on the downsampled English and German \emph  {comparable} sets with additional c2c objective. The Multilingual model uses the French and Czech \emph  {translation pairs} as additional data. The results are reported on the full 2016 test set of the \emph  {comparable} portion of Multi30K.\relax }}{144}{figure.caption.48}}
\newlabel{fig:chart}{{5.3}{144}{Comparing models from the Monolingual, Bilingual and Multilingual settings. The Monolingual and Bilingual models are trained on the downsampled English and German \emph {comparable} sets with additional c2c objective. The Multilingual model uses the French and Czech \emph {translation pairs} as additional data. The results are reported on the full 2016 test set of the \emph {comparable} portion of Multi30K.\relax }{figure.caption.48}{}}
\@setckpt{chapters/ConLL/conll2018}{
\setcounter{page}{145}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{3}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{7}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{21}
\setcounter{ALG@rem}{21}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{treecount}{0}
\setcounter{branchcount}{0}
\setcounter{dt@labelid}{0}
\setcounter{DefaultLines}{2}
\setcounter{DefaultDepth}{0}
\setcounter{L@lines}{0}
\setcounter{L@depth}{0}
\setcounter{Item}{4}
\setcounter{Hfootnote}{22}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{85}
\setcounter{eu@}{0}
\setcounter{eu@i}{0}
\setcounter{mkern}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{NAT@ctr}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{section@level}{0}
}
