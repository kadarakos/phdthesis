\contentsline {chapter}{Acknowledgements}{VI}{section*.1}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}General introduction}{1}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Learning representations}{2}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Learning representations of words}{3}{subsection.1.1.2}
\contentsline {subsection}{\numberline {1.1.3}Visually grounded word representations}{4}{subsection.1.1.3}
\contentsline {subsection}{\numberline {1.1.4}Visually grounded sentence representations}{6}{subsection.1.1.4}
\contentsline {subsection}{\numberline {1.1.5}Visual modality briding between languages}{7}{subsection.1.1.5}
\contentsline {section}{\numberline {1.2}Background: Distributed linguistic representations}{8}{section.1.2}
\contentsline {section}{\numberline {1.3}Grounded and multilingual representations}{10}{section.1.3}
\contentsline {paragraph}{Images bridging languages}{11}{section.1.3}
\contentsline {paragraph}{Contributions}{12}{section.1.3}
\contentsline {section}{\numberline {1.4}Distributed word-representations}{13}{section.1.4}
\contentsline {subsection}{\numberline {1.4.1}Count-based approaches}{13}{subsection.1.4.1}
\contentsline {subsection}{\numberline {1.4.2}Prediction-based approaches}{14}{subsection.1.4.2}
\contentsline {subsubsection}{Neural language models}{14}{section*.4}
\contentsline {subsubsection}{Efficient linear models}{17}{equation.1.4.3}
\contentsline {section}{\numberline {1.5}Visually grounded representations of words}{18}{section.1.5}
\contentsline {subsection}{\numberline {1.5.1}Language and perception}{18}{subsection.1.5.1}
\contentsline {subsection}{\numberline {1.5.2}Combined distributional and visual spaces}{20}{subsection.1.5.2}
\contentsline {paragraph}{Our contribution}{23}{subsection.1.5.2}
\contentsline {section}{\numberline {1.6}From words to sentences}{24}{section.1.6}
\contentsline {paragraph}{Transferable sentence representations}{26}{section.1.6}
\contentsline {section}{\numberline {1.7}Visually grounded sentence representations}{29}{section.1.7}
\contentsline {paragraph}{Note on data sets}{30}{section.1.7}
\contentsline {paragraph}{Our contribution}{31}{section.1.7}
\contentsline {section}{\numberline {1.8}Visually grounded multilingual representations}{32}{section.1.8}
\contentsline {subsection}{\numberline {1.8.1}Bilingual lexicon induction}{32}{subsection.1.8.1}
\contentsline {subsection}{\numberline {1.8.2}Image pivots for translation}{34}{subsection.1.8.2}
\contentsline {subsection}{\numberline {1.8.3}Multi-view perspective}{34}{subsection.1.8.3}
\contentsline {paragraph}{Our contribution}{35}{subsection.1.8.3}
\contentsline {section}{\numberline {1.9}Interpreting continuous representations}{36}{section.1.9}
\contentsline {paragraph}{Our contribution}{39}{section.1.9}
\contentsline {section}{\numberline {1.10}Published work}{39}{section.1.10}
\contentsline {subsection}{\numberline {1.10.1}Chapters}{39}{subsection.1.10.1}
\contentsline {subsection}{\numberline {1.10.2}Other publications completed during my PhD}{40}{subsection.1.10.2}
\contentsline {chapter}{\numberline {2}Learning word meanings from images of natural scenes}{43}{chapter.2}
\contentsline {paragraph}{Abstract}{43}{chapter.2}
\contentsline {paragraph}{This chapter is based on}{45}{chapter.2}
\contentsline {section}{\numberline {2.1}Introduction}{46}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Cross-situational learning}{46}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Learning meanings from images}{48}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Our study}{50}{subsection.2.1.3}
\contentsline {section}{\numberline {2.2}Word learning model}{51}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Visual input}{52}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Learning algorithm}{54}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Baseline models}{56}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Experiments}{57}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Image datasets}{57}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Word similarity experiments}{58}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Effect of concreteness on similarity judgments}{59}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}Word production}{61}{subsection.2.3.4}
\contentsline {subsubsection}{Multi-word image descriptions.}{61}{section*.8}
\contentsline {subsubsection}{Single-concept image descriptions}{62}{figure.caption.9}
\contentsline {section}{\numberline {2.4}Results}{65}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Word similarity}{65}{subsection.2.4.1}
\contentsline {subsubsection}{Concreteness}{66}{table.caption.12}
\contentsline {subsection}{\numberline {2.4.2}Word production}{69}{subsection.2.4.2}
\contentsline {subsubsection}{Multi-word image descriptors}{70}{section*.15}
\contentsline {subsubsection}{Single-concept image descriptors}{71}{table.caption.16}
\contentsline {section}{\numberline {2.5}Discussion and conclusion}{74}{section.2.5}
\contentsline {chapter}{\numberline {3}Representation of linguistic form and function in recurrent neural networks}{77}{chapter.3}
\contentsline {paragraph}{abstract}{77}{chapter.3}
\contentsline {section}{\numberline {3.1}Introduction}{78}{section.3.1}
\contentsline {section}{\numberline {3.2}Related work}{80}{section.3.2}
\contentsline {section}{\numberline {3.3}Models}{84}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Gated Recurrent Neural Networks}{85}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Imaginet}{86}{subsection.3.3.2}
\contentsline {subsection}{\numberline {3.3.3}Unimodal language model}{88}{subsection.3.3.3}
\contentsline {subsection}{\numberline {3.3.4}Sum of word embeddings}{88}{subsection.3.3.4}
\contentsline {section}{\numberline {3.4}Experiments}{88}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Computing Omission Scores}{89}{subsection.3.4.1}
\contentsline {subsection}{\numberline {3.4.2}Omission score distributions}{91}{subsection.3.4.2}
\contentsline {subsection}{\numberline {3.4.3}Beyond Lexical Cues}{95}{subsection.3.4.3}
\contentsline {subsubsection}{Sensitivity to grammatical function}{98}{figure.caption.25}
\contentsline {subsubsection}{Sensitivity to linear structure}{100}{figure.caption.26}
\contentsline {subsection}{\numberline {3.4.4}Lexical versus abstract contexts}{101}{subsection.3.4.4}
\contentsline {section}{\numberline {3.5}Discussion}{106}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Generalizing to other architectures}{106}{subsection.3.5.1}
\contentsline {subsection}{\numberline {3.5.2}Future directions}{107}{subsection.3.5.2}
\contentsline {chapter}{\numberline {4}Imagination Improves Multimodal Translation}{109}{chapter.4}
\contentsline {paragraph}{abstract}{109}{chapter.4}
\contentsline {section}{\numberline {4.1}Introduction}{110}{section.4.1}
\contentsline {section}{\numberline {4.2}Problem Formulation}{113}{section.4.2}
\contentsline {section}{\numberline {4.3}Imagination Model}{114}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Shared Encoder}{114}{subsection.4.3.1}
\contentsline {subsection}{\numberline {4.3.2}Neural Machine Translation Decoder}{115}{subsection.4.3.2}
\contentsline {subsection}{\numberline {4.3.3}Imaginet Decoder}{117}{subsection.4.3.3}
\contentsline {section}{\numberline {4.4}Data}{118}{section.4.4}
\contentsline {section}{\numberline {4.5}Experiments}{119}{section.4.5}
\contentsline {subsection}{\numberline {4.5.1}Hyperparameters}{119}{subsection.4.5.1}
\contentsline {subsection}{\numberline {4.5.2}In-domain experiments}{120}{subsection.4.5.2}
\contentsline {subsection}{\numberline {4.5.3}External described image data}{121}{subsection.4.5.3}
\contentsline {subsection}{\numberline {4.5.4}External parallel text data}{123}{subsection.4.5.4}
\contentsline {subsection}{\numberline {4.5.5}Ensemble results}{124}{subsection.4.5.5}
\contentsline {subsection}{\numberline {4.5.6}Multi30K 2017 results}{125}{subsection.4.5.6}
\contentsline {subsection}{\numberline {4.5.7}Qualitative examples}{126}{subsection.4.5.7}
\contentsline {section}{\numberline {4.6}Discussion}{126}{section.4.6}
\contentsline {subsection}{\numberline {4.6.1}Does the model learn grounded representations?}{126}{subsection.4.6.1}
\contentsline {subsection}{\numberline {4.6.2}The effect of visual feature vectors}{127}{subsection.4.6.2}
\contentsline {section}{\numberline {4.7}Related work}{129}{section.4.7}
\contentsline {section}{\numberline {4.8}Conclusion}{131}{section.4.8}
\contentsline {chapter}{\numberline {5}Lessons learned in multilingual grounded language learning}{133}{chapter.5}
\contentsline {paragraph}{abstract}{133}{chapter.5}
\contentsline {section}{\numberline {5.1}Introduction}{134}{section.5.1}
\contentsline {section}{\numberline {5.2}Related work}{137}{section.5.2}
\contentsline {section}{\numberline {5.3}Multilingual grounded learning}{140}{section.5.3}
\contentsline {paragraph}{Implementation.}{142}{figure.caption.41}
\contentsline {section}{\numberline {5.4}Experimental setup}{143}{section.5.4}
\contentsline {paragraph}{Datasets.}{143}{table.caption.42}
\contentsline {paragraph}{Evaluation.}{144}{table.caption.42}
\contentsline {section}{\numberline {5.5}Bilingual Experiments}{144}{section.5.5}
\contentsline {subsection}{\numberline {5.5.1}Reproducing \citet {gella2017image}}{144}{subsection.5.5.1}
\contentsline {subsection}{\numberline {5.5.2}Translations vs.\ independent captions}{147}{subsection.5.5.2}
\contentsline {subsection}{\numberline {5.5.3}Overlapping vs.\ non-overlapping images}{148}{subsection.5.5.3}
\contentsline {section}{\numberline {5.6}Multilingual experiments}{150}{section.5.6}
\contentsline {subsection}{\numberline {5.6.1}Translation vs.\ independent captions}{151}{subsection.5.6.1}
\contentsline {subsection}{\numberline {5.6.2}High-to-low resource transfer}{151}{subsection.5.6.2}
\contentsline {subsection}{\numberline {5.6.3}Bilingual vs. multilingual}{152}{subsection.5.6.3}
\contentsline {section}{\numberline {5.7}Conclusions}{153}{section.5.7}
\contentsline {chapter}{\numberline {6}Revisiting the Hierarchical Multiscale LSTM}{155}{chapter.6}
\contentsline {section}{\numberline {6.1}Pre-amble}{155}{section.6.1}
\contentsline {paragraph}{Abstract}{158}{table.caption.51}
\contentsline {section}{\numberline {6.2}Introduction}{159}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}The importance of reproducibility}{160}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}The importance of interpretability}{161}{subsection.6.2.2}
\contentsline {section}{\numberline {6.3}Hierarchical Multiscale LSTM}{164}{section.6.3}
\contentsline {paragraph}{HMLSTM --}{165}{AMS.57}
\contentsline {paragraph}{Bottom Layer --}{165}{AMS.57}
\contentsline {paragraph}{Top Layer --}{166}{equation.6.3.2}
\contentsline {paragraph}{Middle layers --}{166}{equation.6.3.4}
\contentsline {paragraph}{Output gate --}{167}{equation.6.3.6}
\contentsline {section}{\numberline {6.4}Experiments}{168}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Experimental setup}{168}{subsection.6.4.1}
\contentsline {paragraph}{Character-level Penn Treebank --}{170}{subsection.6.4.1}
\contentsline {paragraph}{Text8 --}{171}{subsection.6.4.1}
\contentsline {subsection}{\numberline {6.4.2}Ablation factors}{171}{subsection.6.4.2}
\contentsline {section}{\numberline {6.5}Experimental Results}{174}{section.6.5}
\contentsline {subsection}{\numberline {6.5.1}Reproducing language modeling results}{174}{subsection.6.5.1}
\contentsline {subsection}{\numberline {6.5.2}Ablation results}{176}{subsection.6.5.2}
\contentsline {paragraph}{Layer normalization and learning-rate schedule --}{176}{table.caption.59}
\contentsline {paragraph}{Sensitivity to alpha --}{177}{table.caption.59}
\contentsline {paragraph}{Architectural modification: top-down connection and simpler output --}{177}{table.caption.59}
\contentsline {paragraph}{Alternative architecture: HMRNN --}{177}{table.caption.59}
\contentsline {subsection}{\numberline {6.5.3}Segmentation results}{178}{subsection.6.5.3}
\contentsline {section}{\numberline {6.6}Conclusion}{179}{section.6.6}
\contentsline {section}{\numberline {.1}Vectorized formulation of the HMLSTM}{182}{section.Alph0.1}
\contentsline {paragraph}{}{182}{equation.Alph0.1.12}
\contentsline {section}{\numberline {.2}Vectorized formulation of the HMRNN}{183}{section.Alph0.2}
\contentsline {paragraph}{Bottom layer}{183}{section.Alph0.2}
\contentsline {paragraph}{Top layer}{183}{equation.Alph0.2.13}
\contentsline {paragraph}{Middle layer}{183}{equation.Alph0.2.14}
\contentsline {paragraph}{}{183}{equation.Alph0.2.15}
\contentsline {chapter}{\numberline {A}General discussion and conclusion}{185}{appendix.A}
\contentsline {chapter}{Summary}{187}{section*.62}
\contentsline {chapter}{Publication list}{188}{section*.64}
\contentsline {chapter}{References}{190}{section*.66}
\contentsline {chapter}{TiCC PhD Series}{223}{section*.68}
